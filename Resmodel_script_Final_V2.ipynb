{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0221b1e3",
   "metadata": {},
   "source": [
    "## Step 1: The Foundation (Imports and Setup)\n",
    "Every Python script starts with importing the necessary libraries and setting up the environment. This is like laying the foundation for a house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "696a41f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "\n",
    "# -- Basic Setup --\n",
    "# Set the device to use the GPU if available, otherwise use the CPU.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729b56c2",
   "metadata": {},
   "source": [
    "### Define dataset loader\n",
    "\n",
    "PyTorch uses a Dataset object to handle data loading. Since our model will take three different kinds of input (sensor data, image 1, and image 2), we need to create a special class that tells PyTorch how to retrieve one sample of each, along with its corresponding label.\n",
    "\n",
    "This class will have three essential methods:\n",
    "\n",
    "__init__: Initializes the dataset by storing our feature and label arrays.\n",
    "\n",
    "__len__: Returns the total number of samples in the dataset.\n",
    "\n",
    "__getitem__: Fetches a single data sample at a given index.\n",
    "\n",
    "Here is the code for it. Add this to your script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ebd8185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset loader\n",
    "class CustomDatasetRes(Dataset):\n",
    "    def __init__(self, features1, features2, features3, labels):\n",
    "        self.features1 = features1\n",
    "        self.features2 = features2\n",
    "        self.features3 = features3\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features1)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.features1[index], self.features2[index], self.features3[index], self.labels[index]\n",
    "    \n",
    "# Define a simplified dataset loader for sensor data only\n",
    "class SensorDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03702557",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "Next, we'll add a few helper functions. These functions will perform common tasks that we'll need later, like displaying results, scaling data, and ensuring our experiments are reproducible.\n",
    "\n",
    "1. display_result\n",
    "\n",
    "This function takes the true labels (y_test) and the model's predicted labels (y_pred) and prints out standard performance metrics like accuracy, precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e6414e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_result(y_test, y_pred):\n",
    "    print('Accuracy score : ', accuracy_score(y_test, y_pred))\n",
    "    print('Precision score : ', precision_score(y_test, y_pred, average='weighted'))\n",
    "    print('Recall score : ', recall_score(y_test, y_pred, average='weighted'))\n",
    "    print('F1 score : ', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75a5531",
   "metadata": {},
   "source": [
    "2. scaled_data\n",
    "\n",
    "This function uses Scikit-learn's StandardScaler to normalize the sensor (CSV) data. Scaling is crucial because it ensures that features with larger value ranges don't dominate the learning process. Notice there are two functions with the same name in the original code. In Python, the last definition of a function is the one that gets used. We will add both for completeness, but just know that the first one is effectively overwritten by the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adc0678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "def scaled_data(X_train):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    return X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d51f72",
   "metadata": {},
   "source": [
    "3. set_seed\n",
    "\n",
    "This is a very important function for reproducibility. Machine learning involves a lot of randomness (e.g., initializing model weights, shuffling data). By setting a \"seed,\" we ensure that the sequence of random numbers is the same every time we run the code, which means we'll get the exact same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93f4630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=0):\n",
    "    # Sets the environment variable for Python's hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    # Sets the seed for NumPy's random number generator\n",
    "    np.random.seed(seed)\n",
    "    # Sets the seed for Python's built-in random module\n",
    "    random.seed(seed)\n",
    "    # Sets the seed for PyTorch's random number generator\n",
    "    torch.manual_seed(seed)\n",
    "    # If using a GPU, sets the seed for all CUDA devices\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
    "    # Ensures deterministic behavior in cuDNN (CUDA Deep Neural Network library)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdf1683",
   "metadata": {},
   "source": [
    "### loading and preprocessing the data.\n",
    "\n",
    "The function loadClientsData is designed for a federated learning scenario. It reads data from separate files for each participant (or \"client\"), cleans it, aligns the different data types (sensor vs. image), and splits it into training and testing sets for each client.\n",
    "\n",
    "Because this function is quite long, we'll build it in a few parts.\n",
    "\n",
    "#### Part 1: Initializing and Processing Training Data\n",
    "First, we'll define the function, list the subject IDs we want to load, and create empty dictionaries to store each client's data. Then, we'll start a loop to process each subject one by one. Inside the loop, we'll begin by loading and cleaning the training data.\n",
    "\n",
    "This involves:\n",
    "\n",
    "Reading the sensor data from a CSV file.\n",
    "\n",
    "Removing rows with missing values and any duplicate rows.\n",
    "\n",
    "Dropping columns that we don't need (like the 'Infrared' sensor readings).\n",
    "\n",
    "Loading the corresponding image, label, and timestamp data from .npy files.\n",
    "\n",
    "#### Part 2: Aligning and Preparing Training Data\n",
    "After loading the raw data, we face a common problem: the datasets don't perfectly match. Because we dropped rows with missing values from the sensor (CSV) data, there are now timestamps in our image data that no longer have a corresponding entry in the sensor data.\n",
    "\n",
    "We need to align them by removing the image samples that don't have a matching sensor reading.\n",
    "\n",
    "After alignment, we'll prepare the data for the model:\n",
    "\n",
    "Set the seed for reproducibility.\n",
    "\n",
    "Separate features from labels.\n",
    "\n",
    "One-hot encode the labels, converting them into a format suitable for the model's output layer (e.g., class 3 becomes [0, 0, 0, 1, 0, ...]).\n",
    "\n",
    "Scale the numeric sensor data and the image pixel values.\n",
    "\n",
    "Reshape the images to the format expected by the convolutional layers.\n",
    "\n",
    "#### Part 3: Processing the Test Data and Finalizing the Function\n",
    "The logic here is identical to what we just did for the training data:\n",
    "\n",
    "Load the test sensor data (_test.csv) and test image data (_test.npy).\n",
    "\n",
    "Clean the sensor data by removing missing values and unnecessary columns.\n",
    "\n",
    "Align the test image data with the cleaned test sensor data.\n",
    "\n",
    "Prepare the aligned test data (one-hot encode labels, scale features, reshape images).\n",
    "\n",
    "Store all the processed training and test arrays into our dictionaries.\n",
    "\n",
    "Increment the clint_index and repeat the process for the next subject.\n",
    "\n",
    "After the loop finishes, the function returns all the dictionaries containing the data for every client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f6095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSensorClientsData_from_csv(file_path):\n",
    "    \"\"\"\n",
    "    Loads, processes, and splits sensor data from a single combined CSV file,\n",
    "    treating each sensor location as a separate client and handling specified\n",
    "    data exclusions.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. Load Data and Clean Column Headers ---\n",
    "    print(f\"Loading data from {file_path}...\")\n",
    "    df = pd.read_csv(file_path, header=[0, 1])\n",
    "\n",
    "    # Clean the multi-level column names\n",
    "    cleaned_columns = []\n",
    "    last_val = ''\n",
    "    for col_l1, col_l2 in df.columns:\n",
    "        if 'Unnamed' in col_l1:\n",
    "            col_l1 = last_val\n",
    "        else:\n",
    "            last_val = col_l1.strip()\n",
    "            col_l1 = last_val\n",
    "        if col_l1 == col_l2:\n",
    "            cleaned_columns.append(col_l1)\n",
    "        else:\n",
    "            cleaned_columns.append(f\"{col_l1}_{col_l2.strip()}\")\n",
    "    df.columns = cleaned_columns\n",
    "    print(\"Column headers cleaned successfully.\")\n",
    "    print(f\"Data shape after loading: {df.shape}\\n\")\n",
    "   \n",
    "    # --- 2. Apply All Data Exclusions ---\n",
    "    print(\"Applying data exclusion rules...\")\n",
    "    \n",
    "    # Rule 1: Skip all data from subjects 5 and 9\n",
    "    initial_rows = len(df)\n",
    "    df = df[~df['Subject'].isin([5, 9])]\n",
    "    print(f\"  - Removed {initial_rows - len(df)} rows for Subjects 5 and 9.\")\n",
    "    \n",
    "    # Rule 2: Skip all data from Activity 5 of Subject 2\n",
    "    initial_rows = len(df)\n",
    "    df = df[~((df['Subject'] == 2) & (df['Activity'] == 5))]\n",
    "    print(f\"  - Removed {initial_rows - len(df)} rows for Subject 2, Activity 5.\")\n",
    "\n",
    "    # Rule 3: Skip the two missing trials in Activity 11 of Subject 8\n",
    "    initial_rows = len(df)\n",
    "    df = df[~((df['Subject'] == 8) & (df['Activity'] == 11) & (df['Trial'].isin([2, 3])))]\n",
    "    print(f\"  - Removed {initial_rows - len(df)} rows for Subject 8, Activity 11, Trials 2 & 3.\")\n",
    "\n",
    "    # --- 3. Preprocess and Split Data ---\n",
    "    # Drop columns that are not needed for modeling\n",
    "    cols_to_drop = [col for col in df.columns if 'Infrared' in col]\n",
    "    cols_to_drop.extend(['TimeStamps_Time', 'Trial', 'Tag'])\n",
    "    df.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
    "    \n",
    "    # Handle any remaining missing values\n",
    "    df.dropna(inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Split data by the remaining subjects for training and testing\n",
    "    # Note: Subjects 5 and 9 will not be in either set.\n",
    "    train_subjects = [s for s in range(1, 14) if s not in [5, 9]]\n",
    "    test_subjects = [s for s in range(14, 18)]\n",
    "    \n",
    "    train_df = df[df['Subject'].isin(train_subjects)].copy()\n",
    "    test_df = df[df['Subject'].isin(test_subjects)].copy()\n",
    "\n",
    "    # --- 4. Define Clients and Process Data ---\n",
    "    sensor_clients = {\n",
    "        'Ankle_IMU': [\n",
    "            'AnkleAccelerometer_x-axis (g)', 'AnkleAccelerometer_y-axis (g)', 'AnkleAccelerometer_z-axis (g)',\n",
    "            'AnkleAngularVelocity_x-axis (deg/s)', 'AnkleAngularVelocity_y-axis (deg/s)', 'AnkleAngularVelocity_z-axis (deg/s)',\n",
    "            'AnkleLuminosity_illuminance (lx)'\n",
    "        ],\n",
    "        'Pocket_IMU': [\n",
    "            'RightPocketAccelerometer_x-axis (g)', 'RightPocketAccelerometer_y-axis (g)', 'RightPocketAccelerometer_z-axis (g)',\n",
    "            'RightPocketAngularVelocity_x-axis (deg/s)', 'RightPocketAngularVelocity_y-axis (deg/s)', 'RightPocketAngularVelocity_z-axis (deg/s)',\n",
    "            'RightPocketLuminosity_illuminance (lx)'\n",
    "        ],\n",
    "        'Belt_IMU': [\n",
    "            'BeltAccelerometer_x-axis (g)', 'BeltAccelerometer_y-axis (g)', 'BeltAccelerometer_z-axis (g)',\n",
    "            'BeltAngularVelocity_x-axis (deg/s)', 'BeltAngularVelocity_y-axis (deg/s)', 'BeltAngularVelocity_z-axis (deg/s)',\n",
    "            'BeltLuminosity_illuminance (lx)'\n",
    "        ],\n",
    "        'Neck_IMU': [\n",
    "            'NeckAccelerometer_x-axis (g)', 'NeckAccelerometer_y-axis (g)', 'NeckAccelerometer_z-axis (g)',\n",
    "            'NeckAngularVelocity_x-axis (deg/s)', 'NeckAngularVelocity_y-axis (deg/s)', 'NeckAngularVelocity_z-axis (deg/s)',\n",
    "            'NeckLuminosity_illuminance (lx)'\n",
    "        ],\n",
    "        'Wrist_IMU': [\n",
    "            'WristAccelerometer_x-axis (g)', 'WristAccelerometer_y-axis (g)', 'WristAccelerometer_z-axis (g)',\n",
    "            'WristAngularVelocity_x-axis (deg/s)', 'WristAngularVelocity_y-axis (deg/s)', 'WristAngularVelocity_z-axis (deg/s)',\n",
    "            'WristLuminosity_illuminance (lx)'\n",
    "        ]\n",
    "        #,\n",
    "        #'EEG': ['BrainSensor']\n",
    "    }\n",
    "    \n",
    "    X_train_splits, X_test_splits = {}, {}\n",
    "    Y_train_splits, Y_test_splits = {}, {}\n",
    "    \n",
    "    num_classes = 11 # 11 activities\n",
    "\n",
    "    print(\"\\nProcessing data for each sensor client...\")\n",
    "    for client_index, (client_name, columns) in enumerate(sensor_clients.items()):\n",
    "        print(f\"  - Client {client_index}: {client_name}\")\n",
    "        \n",
    "        # Select data for the current client\n",
    "        X_train = train_df[columns].values\n",
    "        # ActivityIDs are 1-11, map to 0-10 for zero-based indexing\n",
    "        y_train = train_df['Activity'].values - 1 \n",
    "        \n",
    "        X_test = test_df[columns].values\n",
    "        y_test = test_df['Activity'].values - 1\n",
    "\n",
    "        # Scale the features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        set_seed() # Set seed for reproducibility\n",
    "        \n",
    "        # One-hot encode the labels\n",
    "        Y_train = torch.nn.functional.one_hot(torch.from_numpy(y_train).long(), num_classes).float()\n",
    "        Y_test = torch.nn.functional.one_hot(torch.from_numpy(y_test).long(), num_classes).float()\n",
    "        \n",
    "        # Store the results\n",
    "        X_train_splits[client_index] = X_train_scaled\n",
    "        X_test_splits[client_index] = X_test_scaled\n",
    "        Y_train_splits[client_index] = Y_train\n",
    "        Y_test_splits[client_index] = Y_test\n",
    "\n",
    "    return X_train_splits, X_test_splits, Y_train_splits, Y_test_splits, sensor_clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9e1b50",
   "metadata": {},
   "source": [
    "## Step 2: Client Selection\n",
    "\n",
    "We're making great progress. We've handled all the data loading and preparation. Now, we'll add the functions that form the \"intelligence\" of our federated learning system: client selection.\n",
    "\n",
    "Instead of blindly averaging updates from every client in every round, these methods evaluate each client's performance and contribution. This allows the server to select the most promising or reliable clients to participate in the global model update, potentially leading to faster convergence and a more robust final model.\n",
    "\n",
    "We'll add a series of functions, each calculating a specific metric to judge the clients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5173b0f8",
   "metadata": {},
   "source": [
    "### Client Evaluation Metrics\n",
    "Add all the following functions to your script. Each one calculates a different score based on a client's performance.\n",
    "\n",
    "1. Relative Loss Reduction (RF_loss)\n",
    "\n",
    "This measures how much a client's training loss has dropped from the beginning to the end of a local training round, relative to the client with the biggest drop. A higher score means the client is learning effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca768194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relative_loss_reduction_as_list(client_losses):\n",
    "    \"\"\"\n",
    "    Calculates the relative loss reduction (RF_loss) for each client.\n",
    "    \"\"\"\n",
    "    loss_reduction = {}\n",
    "    for client_id, losses in client_losses.items():\n",
    "        if len(losses) < 2:\n",
    "            raise ValueError(f\"Client {client_id} has less than 2 loss values, cannot calculate RF_loss.\")\n",
    "        loss_start = losses[0]\n",
    "        loss_end = losses[-1]\n",
    "        loss_reduction[client_id] = loss_start - loss_end\n",
    "\n",
    "    max_loss_reduction = max(loss_reduction.values())\n",
    "    if max_loss_reduction == 0:\n",
    "        return [0.0] * len(loss_reduction)  # If no loss reduction, return 0.0 for all clients\n",
    "\n",
    "    rf_losses_list = [\n",
    "        reduction / max_loss_reduction for reduction in loss_reduction.values()\n",
    "    ]\n",
    "    return rf_losses_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f48d0a",
   "metadata": {},
   "source": [
    "2. Relative Training Accuracy (RF_ACC_Train)\n",
    "\n",
    "This measures a client's local training accuracy relative to the client with the highest accuracy. It's a straightforward measure of performance on local data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a82d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relative_train_accuracy(client_acc):\n",
    "    \"\"\"\n",
    "    Calculates the relative training accuracy (RF_Acc_Train) for each client.\n",
    "    \"\"\"\n",
    "    max_acc = max(client_acc.values())\n",
    "    if max_acc == 0:\n",
    "        return [0.0] * len(client_acc)  # If no accuracy, return 0.0 for all clients\n",
    "\n",
    "    rf_accs_train_list = [\n",
    "        acc / max_acc for acc in client_acc.values()\n",
    "    ]\n",
    "    return rf_accs_train_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e977c2",
   "metadata": {},
   "source": [
    "3. Global Validation Accuracy (RF_ACC_Global)\n",
    "\n",
    "This is a more sophisticated metric. It rewards clients for high accuracy on a global test set but penalizes them if their global accuracy is much worse than their local training accuracy (which is a sign of overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3b4108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_global_validation_accuracy(train_acc, global_acc):\n",
    "    \"\"\"\n",
    "    Calculates the global validation accuracy (RF_Acc_Global) based on local training accuracies.\n",
    "    \"\"\"\n",
    "    if set(train_acc.keys()) != set(global_acc.keys()):\n",
    "        raise ValueError(\"Client IDs for train and global accuracy do not match.\")\n",
    "\n",
    "    max_global_acc = max(global_acc.values())\n",
    "    if max_global_acc == 0:\n",
    "        max_global_acc = 1  # Avoid division by zero\n",
    "\n",
    "    global_train_diff = {\n",
    "        client_id: train_acc[client_id] - global_acc[client_id]\n",
    "        for client_id in train_acc\n",
    "    }\n",
    "    max_global_train_diff = max(global_train_diff.values())\n",
    "    if max_global_train_diff == 0:\n",
    "        max_global_train_diff = 1  # Avoid division by zero\n",
    "\n",
    "    rf_acc_global_list = [\n",
    "        (global_acc[client_id] / max_global_acc) - (global_train_diff[client_id] / max_global_train_diff)\n",
    "        for client_id in train_acc\n",
    "    ]\n",
    "    return rf_acc_global_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21270341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relative_validation_accuracy(client_acc):\n",
    "    \"\"\"\n",
    "    Calculates the relative validation accuracy (RF_ACC_Val) for each client.\n",
    "    \"\"\"\n",
    "    # Ensure client_acc is a dictionary, not a list of lists\n",
    "    if not isinstance(client_acc, dict):\n",
    "        raise TypeError(\"Input must be a dictionary of client accuracies.\")\n",
    "        \n",
    "    max_acc = max(client_acc.values())\n",
    "    if max_acc == 0:\n",
    "        return [0.0] * len(client_acc)\n",
    "\n",
    "    return [acc / max_acc for acc in client_acc.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f26f9bf",
   "metadata": {},
   "source": [
    "4. Loss Outliers (P_loss)\n",
    "\n",
    "This function flags clients that are potential negative contributors. If a client's final training loss is significantly higher than the average loss of all clients, it gets a high penalty score. Otherwise, its penalty is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35c66dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss_outliers(client_losses, lambda_loss=1.5):\n",
    "    \"\"\"\n",
    "    Calculates the loss outlier penalty (P_loss) for each client.\n",
    "    \"\"\"\n",
    "    final_losses = {client_id: losses[-1] for client_id, losses in client_losses.items()}\n",
    "    loss_values = np.array(list(final_losses.values()))\n",
    "\n",
    "    mean_loss = np.mean(loss_values)\n",
    "    std_loss = np.std(loss_values)\n",
    "\n",
    "    threshold = mean_loss + lambda_loss * std_loss\n",
    "\n",
    "    max_loss = np.max(loss_values)\n",
    "\n",
    "    if max_loss == 0:\n",
    "        return [0.0] * len(loss_values)\n",
    "\n",
    "    # Identify outliers\n",
    "    loss_outliers = [\n",
    "        final_loss / max_loss if final_loss > threshold else 0.0\n",
    "        for final_loss in loss_values\n",
    "    ]\n",
    "    return loss_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef96a2ac",
   "metadata": {},
   "source": [
    "5. Performance Bias (P_bias)\n",
    "\n",
    "This metric calculates the gap between a client's performance on its own validation data versus its performance on the global validation data. A large gap might indicate that the client's local data is not representative of the overall data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc704c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance_bias(val_acc, global_acc):\n",
    "    \"\"\"\n",
    "    Calculates the performance bias penalty (P_bias).\n",
    "    \"\"\"\n",
    "    if set(val_acc.keys()) != set(global_acc.keys()):\n",
    "        raise ValueError(\"Client IDs for validation and global accuracy do not match.\")\n",
    "\n",
    "    performance_bias_list = []\n",
    "    for client_id in val_acc:\n",
    "        val = val_acc[client_id]\n",
    "        global_val = global_acc[client_id]\n",
    "        max_val = max(val, global_val)\n",
    "\n",
    "        if max_val == 0:\n",
    "            performance_bias = 0\n",
    "        else:\n",
    "            performance_bias = abs(val - global_val) / max_val\n",
    "        performance_bias_list.append(performance_bias)\n",
    "\n",
    "    return performance_bias_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dfd596",
   "metadata": {},
   "source": [
    "Excellent. Now that we have the functions to score each client, we need the final step: the algorithms that use these scores to select which clients will participate in a given round."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626cecd1",
   "metadata": {},
   "source": [
    "### Client Selection Algorithms\n",
    "1. Pareto Optimization\n",
    "\n",
    "This is a powerful technique used when you have multiple, often conflicting, objectives. Instead of combining all metrics into one score, it tries to find a set of clients that represent the best possible trade-offs.\n",
    "\n",
    "A client is considered \"Pareto optimal\" if no other client is better than it across all metrics. The algorithm first finds this set of optimal clients.\n",
    "\n",
    "If there are more optimal clients than needed, it selects a random subset.\n",
    "\n",
    "If there are fewer, it fills the remaining spots by picking the clients with the best-combined performance score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25f90e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pareto_optimization(\n",
    "    rf_loss, rf_acc_train, rf_acc_val, rf_acc_global, p_loss, p_bias, client_num,\n",
    "):\n",
    "    \"\"\"\n",
    "    实现 Pareto 优化，筛选节点。\n",
    "\n",
    "    参数：\n",
    "    - rf_loss (list): 局部训练损失相对下降幅度。\n",
    "    - rf_acc_train (list): 局部训练精度。\n",
    "    - rf_acc_val (list): 局部验证精度。\n",
    "    - rf_acc_global (list): 全局验证精度。\n",
    "    - p_loss (list): 损失异常。\n",
    "    - p_bias (list): 性能偏离。\n",
    "    - client_num (int): 要选出的节点数。\n",
    "\n",
    "    返回：\n",
    "    - selected_clients (list): 选中的 client ID（按输入顺序从 0 开始）。\n",
    "    \"\"\"\n",
    "    print(\"=== Pareto Optimization: Start ===\")\n",
    "    print(\"Input rf_loss:\", [f\"{x:.2f}\" for x in rf_loss])\n",
    "    print(\"Input rf_acc_train:\", [f\"{x:.2f}\" for x in rf_acc_train])\n",
    "    print(\"Input rf_acc_val:\", [f\"{x:.2f}\" for x in rf_acc_val])\n",
    "    print(\"Input rf_acc_global:\", [f\"{x:.2f}\" for x in rf_acc_global])\n",
    "    print(\"Input p_loss:\", [f\"{x:.2f}\" for x in p_loss])\n",
    "    print(\"Input p_bias:\", [f\"{x:.2f}\" for x in p_bias])\n",
    "    print(f\"Number of clients to select: {client_num}\")\n",
    "\n",
    "    # Ensure all arrays are numpy arrays\n",
    "    rf_loss = np.array(list(rf_loss))\n",
    "    rf_acc_train = rf_acc_train.detach().cpu().numpy() if isinstance(rf_acc_train, torch.Tensor) else np.array(rf_acc_train)\n",
    "    rf_acc_val = rf_acc_val.detach().cpu().numpy() if isinstance(rf_acc_val, torch.Tensor) else np.array(rf_acc_val)\n",
    "    rf_acc_global = rf_acc_global.detach().cpu().numpy() if isinstance(rf_acc_global, torch.Tensor) else np.array(rf_acc_global)\n",
    "    p_loss = p_loss.detach().cpu().numpy() if isinstance(p_loss, torch.Tensor) else np.array(p_loss)\n",
    "    p_bias = p_bias.detach().cpu().numpy() if isinstance(p_bias, torch.Tensor) else np.array(p_bias)\n",
    "\n",
    "    print(\"Converted all inputs to numpy arrays.\")\n",
    "\n",
    "    # Construct data matrix\n",
    "    data = np.array([rf_loss, rf_acc_train, rf_acc_val, rf_acc_global, -p_loss, -p_bias]).T\n",
    "    print(f\"Constructed data matrix for Pareto: shape={data.shape}\")\n",
    "\n",
    "    # Pareto front selection\n",
    "    def is_dominated(point, others):\n",
    "        \"\"\"判断 point 是否被 others 支配\"\"\"\n",
    "        return any(np.all(other >= point) and np.any(other > point) for other in others)\n",
    "\n",
    "    pareto_indices = [\n",
    "        i for i, point in enumerate(data) if not is_dominated(point, np.delete(data, i, axis=0))\n",
    "    ]\n",
    "    pareto_clients = pareto_indices\n",
    "    print(f\"Pareto front client indices: {pareto_clients}\")\n",
    "\n",
    "    # If more Pareto clients than needed, randomly select\n",
    "    if len(pareto_clients) > client_num:\n",
    "        selected = random.sample(pareto_clients, client_num)\n",
    "        print(f\"More Pareto clients than needed. Randomly selected: {selected}\")\n",
    "        print(\"=== Pareto Optimization: End ===\")\n",
    "        return [int(x) for x in selected]\n",
    "\n",
    "    # If fewer Pareto clients, fill with best scores\n",
    "    remaining_slots = client_num - len(pareto_clients)\n",
    "    pareto_scores = [0.4 * rf_loss[i] + 0.6 * rf_acc_global[i] for i in range(len(rf_loss))]\n",
    "    print(\"Pareto scores for all clients:\", [f\"{x:.2f}\" for x in pareto_scores])\n",
    "    sorted_indices = np.argsort(pareto_scores)[::-1]  # Descending order\n",
    "    print(\"Sorted indices by Pareto score:\", [int(x) for x in sorted_indices])\n",
    "\n",
    "    selected_clients = set(pareto_clients)\n",
    "    print(f\"Initial selected clients (Pareto front): {[int(x) for x in selected_clients]}\")\n",
    "    for i in sorted_indices:\n",
    "        if len(selected_clients) >= client_num:\n",
    "            break\n",
    "        if i not in selected_clients:\n",
    "            selected_clients.add(int(i))\n",
    "            print(f\"Added client {int(i)} to fill remaining slots.\")\n",
    "            # If we have filled all slots, we can stop\n",
    "            if len(selected_clients) >= client_num:\n",
    "                break\n",
    "\n",
    "    print(f\"Final selected clients: {[int(x) for x in selected_clients]}\")\n",
    "    print(\"=== Pareto Optimization: End ===\")\n",
    "    return [int(x) for x in selected_clients]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ebf65c",
   "metadata": {},
   "source": [
    "2. Weighted Sum Method (5RF)\n",
    "\n",
    "This is a more straightforward approach. It calculates a single comprehensive score for each client by taking a weighted sum of all the metrics. Clients with the highest final scores are selected. The weights (0.2, 0.1, 0.3, etc.) determine the importance of each metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb04b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_clients_with5RF(rf_loss, rf_acc_train, rf_acc_val, rf_acc_global, p_loss, p_bias, client_num):\n",
    "    rf_loss = np.array(list(rf_loss))\n",
    "    rf_acc_train = np.array(rf_acc_train)\n",
    "    rf_acc_val = np.array(rf_acc_val)\n",
    "    rf_acc_global = np.array(rf_acc_global)\n",
    "    p_loss = np.array(p_loss)\n",
    "    p_bias = np.array(p_bias)\n",
    "\n",
    "    # Calculate a single weighted score for each client\n",
    "    scores = (\n",
    "            0.2 * rf_loss +\n",
    "            0.1 * rf_acc_train +\n",
    "            0.2 * rf_acc_val +\n",
    "            0.3 * rf_acc_global -\n",
    "            0.1 * p_loss -\n",
    "            0.1 * p_bias\n",
    "    )\n",
    "    origin_scores = scores\n",
    "    # Get the indices of the clients with the highest scores\n",
    "    top_client_ids = np.argsort(scores)[::-1][:client_num]  # Sort descending and take the top N\n",
    "    return top_client_ids.tolist(), origin_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee125dce",
   "metadata": {},
   "source": [
    "## Step 2: The AI's Brain (The Model Definition)\n",
    "We have the data pipeline and the client selection logic. Now it's time to build the brain of the operation: the neural network model itself.\n",
    "\n",
    "The model, ModelCSVIMG, is a multi-modal neural network. This means it's designed to accept and process multiple types of data at once. It has three distinct input branches:\n",
    "\n",
    "One for the numerical sensor (CSV) data.\n",
    "\n",
    "One for the images from camera 1.\n",
    "\n",
    "One for the images from camera 2.\n",
    "\n",
    "The features extracted from each branch are then combined (fused) and passed to a final set of layers that perform the classification. The original code contains a few versions of the architecture; we will use the final, most complex one.\n",
    "\n",
    "Add the complete model class to your script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c03f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SensorModel(nn.Module):\n",
    "    def __init__(self, num_csv_features):\n",
    "        super(SensorModel, self).__init__()\n",
    "        # This is Branch 1 from your original model\n",
    "        self.csv_fc_1 = nn.Linear(num_csv_features, 2000)\n",
    "        self.csv_bn_1 = nn.BatchNorm1d(2000)\n",
    "        self.csv_fc_2 = nn.Linear(2000, 600)\n",
    "        self.csv_bn_2 = nn.BatchNorm1d(600)\n",
    "        self.csv_dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        # Final classification layer\n",
    "        self.output_layer = nn.Linear(600, 11) # 11 output classes for 11 activities\n",
    "\n",
    "    def forward(self, x_csv):\n",
    "        x_csv = F.relu(self.csv_bn_1(self.csv_fc_1(x_csv)))\n",
    "        x_csv = F.relu(self.csv_bn_2(self.csv_fc_2(x_csv)))\n",
    "        x_csv = self.csv_dropout(x_csv)\n",
    "        \n",
    "        # Final output with softmax for classification\n",
    "        x = F.softmax(self.output_layer(x_csv), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "218bbd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCSVIMG(nn.Module):\n",
    "    def __init__(self, num_csv_features, img_shape1, img_shape2):\n",
    "        super(ModelCSVIMG, self).__init__()\n",
    "\n",
    "        # --- Branch 1: For processing numerical CSV data ---\n",
    "        self.csv_fc_1 = nn.Linear(num_csv_features, 2000)\n",
    "        self.csv_bn_1 = nn.BatchNorm1d(2000)\n",
    "        self.csv_fc_2 = nn.Linear(2000, 600)\n",
    "        self.csv_bn_2 = nn.BatchNorm1d(600)\n",
    "        self.csv_dropout = nn.Dropout(0.2)\n",
    "\n",
    "        # --- Branch 2: For processing images from Camera 1 (CNN) ---\n",
    "        self.img1_conv_1 = nn.Conv2d(in_channels=1, out_channels=18, kernel_size=3, stride=1, padding=1)\n",
    "        self.img1_batch_norm = nn.BatchNorm2d(18)\n",
    "        self.img1_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Flattened features from the CNN go into a fully connected layer\n",
    "        self.img1_fc1 = nn.Linear(18 * 16 * 16, 100)\n",
    "        self.img1_dropout = nn.Dropout(0.2)\n",
    "\n",
    "        # --- Branch 3: For processing images from Camera 2 (identical to Branch 2) ---\n",
    "        self.img2_conv = nn.Conv2d(in_channels=1, out_channels=18, kernel_size=3, stride=1, padding=1)\n",
    "        self.img2_batch_norm = nn.BatchNorm2d(18)\n",
    "        self.img2_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.img2_fc1 = nn.Linear(18 * 16 * 16, 100)\n",
    "        self.img2_dropout = nn.Dropout(0.2)\n",
    "\n",
    "        # --- Fusion and Final Classification Layers ---\n",
    "        # The input size is 600 (from CSV) + 100 (from Image 1) + 100 (from Image 2) = 800\n",
    "        self.fc1 = nn.Linear(800, 1200)\n",
    "        self.dr1 = nn.Dropout(0.2)\n",
    "        # A residual connection is used here: input to fc2 is the original 800 + output of fc1 (1200) = 2000\n",
    "        self.fc2 = nn.Linear(2000, 12) # 12 output classes\n",
    "\n",
    "    def forward(self, x_csv, x_img1, x_img2):\n",
    "        # --- Process CSV data ---\n",
    "        x_csv = F.relu(self.csv_bn_1(self.csv_fc_1(x_csv)))\n",
    "        x_csv = F.relu(self.csv_bn_2(self.csv_fc_2(x_csv)))\n",
    "        x_csv = self.csv_dropout(x_csv)\n",
    "\n",
    "        # --- Process Image 1 data ---\n",
    "        # Reshape image from (batch, height, width, channels) to (batch, channels, height, width)\n",
    "        x_img1 = x_img1.permute(0, 3, 1, 2)\n",
    "        x_img1 = F.relu(self.img1_conv_1(x_img1))\n",
    "        x_img1 = self.img1_batch_norm(x_img1)\n",
    "        x_img1 = self.img1_pool(x_img1)\n",
    "        x_img1 = x_img1.contiguous().view(x_img1.size(0), -1) # Flatten\n",
    "        x_img1 = F.relu(self.img1_fc1(x_img1))\n",
    "        x_img1 = self.img1_dropout(x_img1)\n",
    "\n",
    "        # --- Process Image 2 data ---\n",
    "        x_img2 = x_img2.permute(0, 3, 1, 2)\n",
    "        x_img2 = F.relu(self.img2_conv(x_img2))\n",
    "        x_img2 = self.img2_batch_norm(x_img2)\n",
    "        x_img2 = self.img2_pool(x_img2)\n",
    "        x_img2 = x_img2.contiguous().view(x_img2.size(0), -1) # Flatten\n",
    "        x_img2 = F.relu(self.img2_fc1(x_img2))\n",
    "        x_img2 = self.img2_dropout(x_img2)\n",
    "\n",
    "        # --- Fusion ---\n",
    "        x = torch.cat((x_csv, x_img1, x_img2), dim=1)\n",
    "        residual = x # Keep a copy for the residual connection\n",
    "        \n",
    "        # --- Final layers ---\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dr1(x)\n",
    "        # Concatenate the residual connection\n",
    "        x = torch.cat((residual, x), dim=1)\n",
    "        # Final output with softmax for classification\n",
    "        x = F.softmax(self.fc2(x), dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f10c36",
   "metadata": {},
   "source": [
    "## Step 3: The Teacher (The Server Class)\n",
    "Alright, we're on the home stretch. We have the data, the selection logic, and the model. Now we need to create the actors for our simulation: the Server and the Client. These two classes will control the entire federated learning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4e0220",
   "metadata": {},
   "source": [
    "1. The Server Class\n",
    "\n",
    "The Server is the central coordinator. Its job is to:\n",
    "\n",
    "Hold the main global model.\n",
    "\n",
    "Send the global model to the clients.\n",
    "\n",
    "Receive updates from the selected clients.\n",
    "\n",
    "Aggregate these updates to improve the global model.\n",
    "\n",
    "Evaluate the global model's performance on a held-out test set.\n",
    "\n",
    "Here is the code for the Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7c9959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Server (simplified for sensor-only data)\n",
    "class Server(object):\n",
    "    def __init__(self, model, epoch_size, eval_dataset, num_clients):\n",
    "        self.global_model = model\n",
    "        self.epoch_size = epoch_size\n",
    "        self.num_clients = num_clients\n",
    "        # Use the new SensorDataset\n",
    "        self.serverTestDataSet = SensorDataset(eval_dataset[0], eval_dataset[1])\n",
    "        self.eval_loader = torch.utils.data.DataLoader(self.serverTestDataSet, batch_size=epoch_size)\n",
    "\n",
    "    def model_aggregate(self, weight_accumulator):\n",
    "        for name, data in self.global_model.state_dict().items():\n",
    "            update_per_layer = weight_accumulator[name] * (1/self.num_clients)\n",
    "            if data.type() != update_per_layer.type():\n",
    "                data.add_(update_per_layer.to(torch.int64))\n",
    "            else:\n",
    "                data.add_(update_per_layer)\n",
    "\n",
    "    def model_eval(self):\n",
    "        self.global_model.eval()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        dataset_size = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_id, batch in enumerate(self.eval_loader):\n",
    "                # Simplified data unpacking\n",
    "                data, target = batch\n",
    "                dataset_size += data.size()[0]\n",
    "\n",
    "                data = data.to(device).float()\n",
    "                target = target.to(device).float()\n",
    "                \n",
    "                # Simplified model call\n",
    "                output = self.global_model(data)\n",
    "                total_loss += nn.functional.cross_entropy(output, target, reduction='sum').item()\n",
    "\n",
    "                pred = output.detach().max(1)[1]\n",
    "                correct += pred.eq(target.detach().max(1)[1].view_as(pred)).cpu().sum().item()\n",
    "\n",
    "        acc = 100.0 * (float(correct) / float(dataset_size))\n",
    "        loss = total_loss / dataset_size\n",
    "        return acc, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db4cd42",
   "metadata": {},
   "source": [
    "## The Client Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32410ea",
   "metadata": {},
   "source": [
    "2. The Client Class and Helper Functions\n",
    "\n",
    "The Client represents an individual participant. Its job is to:\n",
    "\n",
    "Receive the global model from the server.\n",
    "\n",
    "Train this model on its own local data for a few epochs.\n",
    "\n",
    "Calculate the change (the diff) between the original model and its newly trained model.\n",
    "\n",
    "Send this diff back to the server.\n",
    "\n",
    "The client's training process is handled by two helper functions: train_one_epoch and validate.\n",
    "\n",
    "Add the Client class and its two helper functions to your script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a5f5799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client (simplified for sensor-only data)\n",
    "class Client(object):\n",
    "    def __init__(self, epoch_size, local_epoch_per_round, train_dataset,val_dataset, id = -1):\n",
    "        self.epoch_size = epoch_size\n",
    "        self.local_epoch_per_round = local_epoch_per_round\n",
    "        self.client_id = id\n",
    "        # Use the new SensorDataset\n",
    "        self.train_dataset = SensorDataset(train_dataset[0], train_dataset[1])\n",
    "        self.train_loader = torch.utils.data.DataLoader(self.train_dataset, batch_size=epoch_size,shuffle=True)\n",
    "        self.eval_dataset = SensorDataset(val_dataset[0], val_dataset[1])\n",
    "        self.eval_loader = torch.utils.data.DataLoader(self.eval_dataset, batch_size=epoch_size,shuffle=False)\n",
    "\n",
    "    def local_train(self, global_model):\n",
    "        # Use the new SensorModel\n",
    "        model = SensorModel(self.train_dataset.features.shape[1])\n",
    "        model = model.to(device)\n",
    "        model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        losses = []\n",
    "        min_loss, max_loss = float('inf'), float('-inf')\n",
    "\n",
    "        for epoch in range(self.local_epoch_per_round):\n",
    "            train_loss, train_acc = train_one_epoch(model, self.train_loader, criterion, optimizer)\n",
    "            if train_loss > max_loss: max_loss = train_loss\n",
    "            if train_loss < min_loss: min_loss = train_loss\n",
    "            losses.append(train_loss)\n",
    "\n",
    "        val_loss, val_acc = validate(model, self.eval_loader, criterion)\n",
    "        print(f\"Client {self.client_id} - Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "        diff = dict()\n",
    "        for name, data in model.state_dict().items():\n",
    "            diff[name] = (data - global_model.state_dict()[name])\n",
    "            \n",
    "        return model, diff, val_acc, val_loss, min_loss, max_loss, losses, train_acc\n",
    "\n",
    "\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_id, batch in enumerate(train_loader):\n",
    "        # Simplified data unpacking\n",
    "        data, target = batch\n",
    "        data = data.to(device).float()\n",
    "        target = target.to(device).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # Simplified model call\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * data.size(0)\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target.max(1)[1]).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_id, batch in enumerate(val_loader):\n",
    "            # Simplified data unpacking\n",
    "            data, target = batch\n",
    "            data = data.to(device).float()\n",
    "            target = target.to(device).float()\n",
    "\n",
    "            # Simplified model call\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            running_loss += loss.item() * data.size(0)\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target.max(1)[1]).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6de9c9f",
   "metadata": {},
   "source": [
    "We are almost there! We've built all the major components. Before we assemble everything in the main training loop, we need to add the last few helper functions.\n",
    "\n",
    "These functions are primarily used for a simpler, baseline client selection strategy (referred to as '4RF' in the code) that calculates a single score for each client and picks the best ones.\n",
    "\n",
    "Add these final utility functions to your script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5083d0",
   "metadata": {},
   "source": [
    "1. Normalize\n",
    "\n",
    "A standard function to scale any number to a range between 0 and 1, given a minimum and maximum value. This is useful for combining metrics that have different scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3aec0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(value, min_value, max_value):\n",
    "    # Avoid division by zero if min and max are the same\n",
    "    if (max_value - min_value) == 0:\n",
    "        return 0\n",
    "    return (value - min_value) / (max_value - min_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1259c438",
   "metadata": {},
   "source": [
    "2. Evaluate Model Score\n",
    "\n",
    "This function calculates a simple, combined score for a client. It's a weighted average of their performance on their local training set and a global validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beb2c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(acc, loss, min_loss, max_loss, oneclient_test_acc, oneclient_test_loss,alpha=0.8, beta=0.8):\n",
    "    normalized_loss = normalize(loss, min_loss, max_loss)\n",
    "    # Score based on local training performance\n",
    "    train_score = alpha * acc + (1 - alpha) * (1 - normalized_loss) # Use (1 - loss) so higher is better\n",
    "\n",
    "    # Score based on global validation performance\n",
    "    val_score = beta * oneclient_test_acc + (1 - beta) * (1 - oneclient_test_loss)\n",
    "\n",
    "    # Final combined score\n",
    "    combined_score = (train_score + val_score) / 2\n",
    "    return combined_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d2e60b",
   "metadata": {},
   "source": [
    "3. Get Top Clients\n",
    "\n",
    "A straightforward function that takes a dictionary of clients and their scores, then returns a list of the top num clients with the highest scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5f5a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_clients(client_dict, num):\n",
    "    # Sort the clients by their score (the dictionary value) in descending order\n",
    "    sorted_clients = sorted(client_dict.items(), key=lambda item: item[1], reverse=True)\n",
    "    # Extract just the IDs (the dictionary key) of the top clients\n",
    "    top_clients = [client[0] for client in sorted_clients[:num]]\n",
    "    return top_clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00c9e3e",
   "metadata": {},
   "source": [
    "4. Dynamic Threshold Selection\n",
    "\n",
    "This is another, more advanced selection method included in the script. It selects clients whose scores are above a dynamic threshold (calculated from the mean and standard deviation of all scores). While not used in the final configuration, we include it for completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8c10e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_nodes_with_dynamic_threshold(node_scores, max_nodes, std_multiplier=1.0):\n",
    "    \"\"\"\n",
    "    Selects nodes using a dynamic threshold based on score distribution.\n",
    "    \"\"\"\n",
    "    if not node_scores:\n",
    "        return []\n",
    "        \n",
    "    scores = np.array(list(node_scores.values()))\n",
    "    \n",
    "    # Calculate the dynamic threshold\n",
    "    mean_score = np.mean(scores)\n",
    "    std_dev = np.std(scores)\n",
    "    dynamic_threshold = mean_score + std_multiplier * std_dev\n",
    "\n",
    "    # Select nodes above the threshold\n",
    "    selected_nodes = [\n",
    "        node_id for node_id, score in node_scores.items() if score >= dynamic_threshold\n",
    "    ]\n",
    "\n",
    "    # If too many nodes were selected, keep only the best ones\n",
    "    if len(selected_nodes) > max_nodes:\n",
    "        selected_nodes = sorted(\n",
    "            selected_nodes, key=lambda node_id: node_scores[node_id], reverse=True\n",
    "        )[:max_nodes]\n",
    "\n",
    "    # If not enough nodes were selected, add the next best ones to meet the quota\n",
    "    if len(selected_nodes) < max_nodes:\n",
    "        remaining_nodes = [\n",
    "            node_id for node_id in node_scores if node_id not in selected_nodes\n",
    "        ]\n",
    "        remaining_nodes = sorted(\n",
    "            remaining_nodes, key=lambda node_id: node_scores[node_id], reverse=True\n",
    "        )\n",
    "        selected_nodes += remaining_nodes[: max_nodes - len(selected_nodes)]\n",
    "\n",
    "    return selected_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc43cf88",
   "metadata": {},
   "source": [
    "## Step 4: Model Trainer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae88ddb8",
   "metadata": {},
   "source": [
    "Here we go. This is the big one. We'll now write the trainValModelCSVIMG function. This function is the conductor of our orchestra—it brings together the data, the model, the server, and the clients to run the entire federated learning simulation from start to finish.\n",
    "\n",
    "Because it's so long and important, we'll build it in three parts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0daed1",
   "metadata": {},
   "source": [
    "### Part 1: Initialization and Starting the Training Loop\n",
    "\n",
    "First, we'll define the function and set everything up. This includes:\n",
    "\n",
    "Creating the global model, the Server, and all the Client objects.\n",
    "\n",
    "Initializing a series of dictionaries to log every possible metric (loss, accuracy, selection scores, etc.) for every client and every round. This is crucial for analyzing the experiment later.\n",
    "\n",
    "Starting the main training loop, which iterates through the communication rounds.\n",
    "\n",
    "Inside the loop, we'll begin the first phase of a round: every client trains locally on the current global model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff2cf43",
   "metadata": {},
   "source": [
    "### Part 2: Client Selection, Aggregation, and Global Evaluation\n",
    "In this part of the trainValModelCSVIMG function, the server performs the following steps:\n",
    "\n",
    "Evaluate: It uses all the metrics gathered from the clients to calculate the advanced performance scores (RF_loss, P_bias, etc.).\n",
    "\n",
    "Select: Based on the chosen selection method (svmethod), it picks the top-performing clients for this round.\n",
    "\n",
    "Aggregate: It averages the model updates (diffs) from only the selected clients to create a new, improved global model.\n",
    "\n",
    "Evaluate Globally: It tests the new global model's performance on the entire held-out test set.\n",
    "\n",
    "Save Best Model: If the new global model is the best one seen so far, its state is saved to a file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85016d00",
   "metadata": {},
   "source": [
    "### Part 3: Final Test and Saving Results\n",
    "Now that the training is finished, we need to do two last things:\n",
    "\n",
    "Load the best model that we saved during training and run a final, definitive test on it. This gives us the final performance numbers for our experiment.\n",
    "\n",
    "Save all the logs we've been collecting into a CSV file. This is essential for creating plots and analyzing the training process, client behavior, and the effectiveness of the selection strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ae16c9",
   "metadata": {},
   "source": [
    "# --- Phase 1: All clients perform local training ---\n",
    "        for client_index in range(total_client):\n",
    "            # Check if the client's data shape matches the server's global model input shape\n",
    "            client_feature_count = clients[client_index].train_dataset.features.shape[1]\n",
    "            global_model_input_features = server.global_model.csv_fc_1.in_features\n",
    "\n",
    "            if client_feature_count != global_model_input_features:\n",
    "                print(f\"Skipping client {client_index} due to feature mismatch ({client_feature_count} features vs global model {global_model_input_features})\")\n",
    "                # Assign default/dummy values for this client's metrics for this round\n",
    "                perEpoch_clients_losses[client_index] = [0]\n",
    "                perEpoch_clients_train_acc[client_index] = 0\n",
    "                perEpoch_clients_local_test_acc[client_index] = 0\n",
    "                diff_client[client_index] = {name: torch.zeros_like(params) for name, params in server.global_model.state_dict().items()}\n",
    "                perEpoch_clients_global_test_acc[client_index] = 0\n",
    "                clients_train_acc[client_index].append(0)\n",
    "                clients_train_loss[client_index].append(0)\n",
    "                clients_test_acc[client_index].append(0)\n",
    "                clients_epoch_selected[client_index].append(0)\n",
    "                continue # Move to the next client\n",
    "\n",
    "            # If shapes match, proceed with training\n",
    "            round_client_model, diff, test_acc_client, loss_client, min_loss, max_loss, losses, train_acc = clients[client_index].local_train(server.global_model)\n",
    "            \n",
    "            # Store results for this client\n",
    "            perEpoch_clients_losses[client_index] = losses\n",
    "            perEpoch_clients_train_acc[client_index] = train_acc\n",
    "            perEpoch_clients_local_test_acc[client_index] = test_acc_client\n",
    "            diff_client[client_index] = diff\n",
    "            \n",
    "            # Evaluate this client's trained model on the SERVER's test set\n",
    "            oneclient_global_test_acc, _ = validate(round_client_model, server.eval_loader, nn.CrossEntropyLoss())\n",
    "            perEpoch_clients_global_test_acc[client_index] = oneclient_global_test_acc\n",
    "            \n",
    "            # Log the local and global test accuracies for this round\n",
    "            clients_train_acc[client_index].append(test_acc_client)\n",
    "            clients_train_loss[client_index].append(loss_client)\n",
    "            clients_test_acc[client_index].append(oneclient_global_test_acc)\n",
    "            clients_epoch_selected[client_index].append(0) # Mark as not selected (yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d12fdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainValModelCSVIMG(model_name, svmethod, total_client, num_clients, epoch, max_acc, epoch_size, local_epoch_per_round, round_early_stop,\n",
    "                        X_train_csv_scaled_splits, X_test_csv_scaled_splits,\n",
    "                        Y_train_csv_splits, Y_test_csv_splits, sensor_clients):\n",
    "    # --- 1. Initialization ---\n",
    "    print(f\"Initializing model and server for {total_client} sensor clients...\")\n",
    "    # Instantiate the global model using the new SensorModel\n",
    "    model_MLP = SensorModel(X_train_csv_scaled_splits[0].shape[1])\n",
    "    model_MLP = model_MLP.to(device)\n",
    "\n",
    "    # The first client's (Ankle_IMU) test data is reserved for the server's global evaluation\n",
    "    # This provides a consistent 7-feature dataset for all evaluations.\n",
    "    server_eval_client_idx = 0\n",
    "    server = Server(model_MLP, epoch_size, [X_test_csv_scaled_splits[server_eval_client_idx], Y_test_csv_splits[server_eval_client_idx]], num_clients)\n",
    "    \n",
    "    # Create a list of all clients using the simplified sensor data\n",
    "    clients = []\n",
    "    for client_index in range(total_client):\n",
    "        clients.append(Client(epoch_size=epoch_size, local_epoch_per_round=local_epoch_per_round,\n",
    "                              train_dataset=[X_train_csv_scaled_splits[client_index], Y_train_csv_splits[client_index]],\n",
    "                              val_dataset=[X_test_csv_scaled_splits[client_index], Y_test_csv_splits[client_index]], \n",
    "                              id=client_index))\n",
    "\n",
    "    # --- Dictionaries for Logging ---\n",
    "    clients_scoresDict = {}\n",
    "    perEpoch_clients_losses = {}\n",
    "    perEpoch_clients_train_acc = {}\n",
    "    perEpoch_clients_local_test_acc = {}\n",
    "    perEpoch_clients_global_test_acc = {}\n",
    "    clients_train_acc = {}\n",
    "    clients_train_loss = {}\n",
    "    clients_test_acc = {}\n",
    "    clients_test_loss = {}\n",
    "    clients_rf_relative_loss_reduction = {}\n",
    "    clients_rf_acc_train = {}\n",
    "    clients_rf_acc_val = {}\n",
    "    clients_rf_global_validation_accuracy = {}\n",
    "    clients_rf_loss_outliers = {}\n",
    "    clients_rf_performance_bias = {}\n",
    "    clients_epoch_selected = {}\n",
    "\n",
    "    for i in range(total_client + 1):  # +1 for the server/global model\n",
    "        clients_train_acc[i], clients_train_loss[i], clients_test_acc[i], clients_test_loss[i] = [], [], [], []\n",
    "        clients_scoresDict[i], clients_rf_relative_loss_reduction[i], clients_rf_acc_train[i] = [], [], []\n",
    "        clients_rf_acc_val[i], clients_rf_global_validation_accuracy[i], clients_rf_loss_outliers[i] = [], [], []\n",
    "        clients_rf_performance_bias[i], clients_epoch_selected[i] = [], []\n",
    "\n",
    "    epoch_count = 0\n",
    "    # --- 2. Main Federated Learning Loop ---\n",
    "    for e in range(epoch):\n",
    "        print(f\"--- Round {e+1}/{epoch} ---\")\n",
    "        if epoch_count >= round_early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "            \n",
    "        diff_client = {}\n",
    "        weight_accumulator = {name: torch.zeros_like(params) for name, params in server.global_model.state_dict().items()}\n",
    "\n",
    "        # --- Phase 1: All clients perform local training ---\n",
    "        for client_index in range(total_client):\n",
    "            round_client_model, diff, test_acc_client, loss_client, min_loss, max_loss, losses, train_acc = clients[client_index].local_train(server.global_model)\n",
    "            \n",
    "            perEpoch_clients_losses[client_index] = losses\n",
    "            perEpoch_clients_train_acc[client_index] = train_acc\n",
    "            perEpoch_clients_local_test_acc[client_index] = test_acc_client\n",
    "            diff_client[client_index] = diff\n",
    "            \n",
    "            # Evaluate this client's trained model on the entire global test set\n",
    "            correct, dataset_size = 0, 0\n",
    "            with torch.no_grad():\n",
    "                for test_data_index in range(total_client): \n",
    "                    test_server_loader = torch.utils.data.DataLoader(\n",
    "                        SensorDataset(X_test_csv_scaled_splits[test_data_index], Y_test_csv_splits[test_data_index]),\n",
    "                        batch_size=epoch_size)\n",
    "                    \n",
    "                    round_client_model.eval()\n",
    "                    for batch_id, batch in enumerate(test_server_loader):\n",
    "                        data, target = batch\n",
    "                        dataset_size += data.size()[0]\n",
    "                        data, target = data.to(device).float(), target.to(device).float()\n",
    "                        \n",
    "                        output = round_client_model(data)\n",
    "                        pred = output.detach().max(1)[1]\n",
    "                        correct += pred.eq(target.detach().max(1)[1].view_as(pred)).cpu().sum().item()\n",
    "\n",
    "            oneclient_global_test_acc = 100.0 * (correct / dataset_size)\n",
    "            perEpoch_clients_global_test_acc[client_index] = oneclient_global_test_acc\n",
    "            \n",
    "            clients_train_acc[client_index].append(test_acc_client)\n",
    "            clients_train_loss[client_index].append(loss_client)\n",
    "            clients_test_acc[client_index].append(oneclient_global_test_acc)\n",
    "            clients_epoch_selected[client_index].append(0)\n",
    "\n",
    "        # --- Phase 2: Server evaluates, selects, and aggregates ---\n",
    "        rf_relative_loss_reduction = calculate_relative_loss_reduction_as_list(perEpoch_clients_losses)\n",
    "        rf_acc_train = calculate_relative_train_accuracy(perEpoch_clients_train_acc)\n",
    "        rf_acc_val = calculate_relative_validation_accuracy(perEpoch_clients_local_test_acc)\n",
    "        rf_global_validation_accuracy = calculate_global_validation_accuracy(perEpoch_clients_train_acc, perEpoch_clients_global_test_acc)\n",
    "        rf_loss_outliers = calculate_loss_outliers(perEpoch_clients_losses)\n",
    "        rf_performance_bias = calculate_performance_bias(perEpoch_clients_local_test_acc, perEpoch_clients_global_test_acc)\n",
    "        \n",
    "        for client_index in range(total_client):\n",
    "            clients_rf_relative_loss_reduction[client_index].append(rf_relative_loss_reduction[client_index])\n",
    "            clients_rf_acc_train[client_index].append(rf_acc_train[client_index])\n",
    "            clients_rf_acc_val[client_index].append(rf_acc_val[client_index])\n",
    "            clients_rf_global_validation_accuracy[client_index].append(rf_global_validation_accuracy[client_index])\n",
    "            clients_rf_loss_outliers[client_index].append(rf_loss_outliers[client_index])\n",
    "            clients_rf_performance_bias[client_index].append(rf_performance_bias[client_index])\n",
    "\n",
    "        # --- Select clients based on the specified method ---\n",
    "        candidates = []\n",
    "        if svmethod == '5RF':\n",
    "            candidates, scores = get_top_clients_with5RF(rf_relative_loss_reduction, rf_acc_train, rf_acc_val,\n",
    "                                                         rf_global_validation_accuracy, rf_loss_outliers, rf_performance_bias,\n",
    "                                                         num_clients)\n",
    "            for index in range(len(scores)):\n",
    "                clients_scoresDict[index].append(scores[index])\n",
    "        elif svmethod == 'pareto':\n",
    "            candidates = pareto_optimization(rf_relative_loss_reduction, rf_acc_train, rf_acc_val,\n",
    "                                              rf_global_validation_accuracy, rf_loss_outliers, rf_performance_bias,\n",
    "                                              num_clients)\n",
    "        elif svmethod == 'random':\n",
    "            candidates = np.random.choice(total_client, num_clients, replace=False)\n",
    "\n",
    "        print(f\"Selected clients for aggregation: {candidates}\")\n",
    "\n",
    "        for selected_client_index in candidates:\n",
    "            clients_epoch_selected[selected_client_index][-1] = 1\n",
    "        \n",
    "        for selected_client_index in candidates:\n",
    "            for name, params in server.global_model.state_dict().items():\n",
    "                weight_accumulator[name].add_(diff_client[selected_client_index][name])\n",
    "        \n",
    "        server.model_aggregate(weight_accumulator)\n",
    "\n",
    "        # --- Phase 3: Evaluate the new global model ---\n",
    "        acc, loss = server.model_eval()\n",
    "        \n",
    "        clients_test_acc[total_client].append(acc)\n",
    "        clients_test_loss[total_client].append(loss)\n",
    "        \n",
    "        print(f\"Round {e+1} Global Model - Accuracy: {acc:.2f}%, Loss: {loss:.4f}\\n\")\n",
    "\n",
    "        epoch_count += 1\n",
    "        if acc > max_acc:\n",
    "            max_acc = acc\n",
    "            print(\"New best model found! Saving model...\")\n",
    "            torch.save(server.global_model.state_dict(),\n",
    "                       f\"./acc_lossFiles/{model_name}_totalClient_{total_client}_NumClient_{num_clients}_epoch_{epoch}_svmethod_{svmethod}.pth\")\n",
    "            epoch_count = 0\n",
    "        \n",
    "    # --- After the training loop, perform a final evaluation on the best model ---\n",
    "    print(\"\\n--- Final Evaluation on Best Model ---\")\n",
    "    model = SensorModel(X_train_csv_scaled_splits[0].shape[1])\n",
    "    model.load_state_dict(torch.load(\n",
    "        f\"./acc_lossFiles/{model_name}_totalClient_{total_client}_NumClient_{num_clients}_epoch_{epoch}_svmethod_{svmethod}.pth\"))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    y_test_all, y_predict_all = [], []\n",
    "    total_loss, correct, dataset_size = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_data_index in range(total_client):\n",
    "            test_server_loader = torch.utils.data.DataLoader(\n",
    "                SensorDataset(X_test_csv_scaled_splits[test_data_index], Y_test_csv_splits[test_data_index]),\n",
    "                batch_size=epoch_size)\n",
    "            for batch_id, batch in enumerate(test_server_loader):\n",
    "                data, target = batch\n",
    "                dataset_size += data.size()[0]\n",
    "                data, target = data.to(device).float(), target.to(device).float()\n",
    "\n",
    "                output = model(data)\n",
    "                total_loss += nn.functional.cross_entropy(output, target, reduction='sum').item()\n",
    "                y_test_all.extend(target.detach().max(1)[1].cpu().numpy())\n",
    "                y_predict_all.extend(output.detach().max(1)[1].cpu().numpy())\n",
    "                pred = output.detach().max(1)[1]\n",
    "                correct += pred.eq(target.detach().max(1)[1].view_as(pred)).cpu().sum().item()\n",
    "\n",
    "    acc = 100.0 * (correct / dataset_size)\n",
    "    loss = total_loss / dataset_size\n",
    "\n",
    "    print(f'Final Best Model Test Accuracy: {acc:.2f}%')\n",
    "    print(f'Final Best Model Test Loss: {loss:.4f}')\n",
    "    print(f'Max accuracy achieved during training: {max_acc:.2f}%')\n",
    "\n",
    "    # --- Save all logged data to a CSV file ---\n",
    "    csv_file_name = f\"./acc_lossFiles/{model_name}_totalClient_{total_client}_NumClient_{num_clients}_epoch_{epoch}_svmethod_{svmethod}.csv\"\n",
    "    \n",
    "    header = ['client_id', 'client_name', 'Epoch', 'local_val_loss', 'local_val_accuracy', 'global_test_loss', 'global_test_accuracy',\n",
    "              'rf_loss', 'rf_acc_train', 'rf_acc_val', 'rf_acc_global', 'p_loss', 'p_bias', 'selected']\n",
    "    \n",
    "    client_name_map = {i: name for i, name in enumerate(sensor_clients.keys())}\n",
    "    client_name_map[total_client] = 'Global_Model'\n",
    "\n",
    "    all_rows = []\n",
    "    for i in range(total_client + 1):\n",
    "        max_epochs = len(clients_test_acc.get(i, []))\n",
    "        for j in range(max_epochs):\n",
    "            row_data = {\n",
    "                'client_id': i,\n",
    "                'client_name': client_name_map[i],\n",
    "                'Epoch': j + 1,\n",
    "                'local_val_loss': clients_train_loss.get(i, [])[j] if i != total_client else '',\n",
    "                'local_val_accuracy': clients_train_acc.get(i, [])[j] if i != total_client else '',\n",
    "                'global_test_loss': clients_test_loss.get(i, [])[j],\n",
    "                'global_test_accuracy': clients_test_acc.get(i, [])[j],\n",
    "                'rf_loss': clients_rf_relative_loss_reduction.get(i, [])[j] if i != total_client else '',\n",
    "                'rf_acc_train': clients_rf_acc_train.get(i, [])[j] if i != total_client else '',\n",
    "                'rf_acc_val': clients_rf_acc_val.get(i, [])[j] if i != total_client else '',\n",
    "                'rf_acc_global': clients_rf_global_validation_accuracy.get(i, [])[j] if i != total_client else '',\n",
    "                'p_loss': clients_rf_loss_outliers.get(i, [])[j] if i != total_client else '',\n",
    "                'p_bias': clients_rf_performance_bias.get(i, [])[j] if i != total_client else '',\n",
    "                'selected': clients_epoch_selected.get(i, [])[j] if i != total_client else ''\n",
    "            }\n",
    "            all_rows.append(row_data)\n",
    "\n",
    "    results_df = pd.DataFrame(all_rows)\n",
    "    results_df.to_csv(csv_file_name, index=False)\n",
    "    print(f\"✅ Results successfully saved to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec6e7cb",
   "metadata": {},
   "source": [
    "We've arrived at the final step! We have all the building blocks in place. The only thing left is to set our experimental parameters and create the main execution block that calls our functions and runs the simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d287713",
   "metadata": {},
   "source": [
    "## Final Step: The main Function and Execution Block\n",
    "This final piece of code does the following:\n",
    "\n",
    "Sets Hyperparameters: Defines all the key variables for the experiment, like the number of clients, epochs, learning rate, etc. It also defines the different scenarios we want to test (e.g., different client selection methods, different data corruption scenarios).\n",
    "\n",
    "Defines a main() function: This function orchestrates the experiment. It loads the client data, then loops through each experimental scenario. For scenarios involving \"model loss,\" it intentionally corrupts the data for some clients (e.g., replacing their sensor data with random noise) to simulate system failures or unreliable participants.\n",
    "\n",
    "Calls trainValModelCSVIMG: For each scenario, it calls our main training function to run a full federated learning simulation.\n",
    "\n",
    "Executes main(): The standard if __name__ == \"__main__\": line ensures that the main function is called when you run the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fdc2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /home/syed/PhD/UP-Fall-FL/dataset/Sensor + Image/sensor.csv...\n",
      "Column headers cleaned successfully.\n",
      "Data shape after loading: (294678, 47)\n",
      "\n",
      "First few rows of the dataset:\n",
      "              TimeStamps_Time  AnkleAccelerometer_x-axis (g)  \\\n",
      "0  2018-07-04T12:04:17.738369                         -1.005   \n",
      "1  2018-07-04T12:04:17.790509                         -1.005   \n",
      "2  2018-07-04T12:04:17.836632                         -1.005   \n",
      "3  2018-07-04T12:04:17.885262                         -1.005   \n",
      "4  2018-07-04T12:04:17.945423                         -1.008   \n",
      "\n",
      "   AnkleAccelerometer_y-axis (g)  AnkleAccelerometer_z-axis (g)  \\\n",
      "0                          0.229                         -0.083   \n",
      "1                          0.228                         -0.082   \n",
      "2                          0.231                         -0.079   \n",
      "3                          0.231                         -0.079   \n",
      "4                          0.229                         -0.072   \n",
      "\n",
      "   AnkleAngularVelocity_x-axis (deg/s)  AnkleAngularVelocity_y-axis (deg/s)  \\\n",
      "0                               -0.671                                0.488   \n",
      "1                               -3.415                               -0.549   \n",
      "2                               -2.622                               -1.402   \n",
      "3                               -2.561                               -2.195   \n",
      "4                               -3.537                               -2.073   \n",
      "\n",
      "   AnkleAngularVelocity_z-axis (deg/s)  AnkleLuminosity_illuminance (lx)  \\\n",
      "0                               -2.683                               0.0   \n",
      "1                                0.122                               0.0   \n",
      "2                               -0.549                               0.0   \n",
      "3                               -1.220                               0.0   \n",
      "4                               -0.305                               0.0   \n",
      "\n",
      "   RightPocketAccelerometer_x-axis (g)  RightPocketAccelerometer_y-axis (g)  \\\n",
      "0                               -0.981                                0.260   \n",
      "1                               -0.981                                0.260   \n",
      "2                               -0.975                                0.282   \n",
      "3                               -0.973                                0.301   \n",
      "4                               -0.973                                0.301   \n",
      "\n",
      "   ...  Infrared1  Infrared2  Infrared3  Infrared4  Infrared5  Infrared6  \\\n",
      "0  ...          1          1          1          1          1          1   \n",
      "1  ...          1          1          1          1          1          1   \n",
      "2  ...          1          1          1          1          1          1   \n",
      "3  ...          1          1          1          1          1          1   \n",
      "4  ...          1          1          1          1          1          1   \n",
      "\n",
      "   Subject  Activity  Trial  Tag  \n",
      "0        1         1      1    7  \n",
      "1        1         1      1    7  \n",
      "2        1         1      1    7  \n",
      "3        1         1      1    7  \n",
      "4        1         1      1    7  \n",
      "\n",
      "[5 rows x 47 columns]\n",
      "Applying data exclusion rules...\n",
      "  - Removed 36109 rows for Subjects 5 and 9.\n",
      "  - Removed 455 rows for Subject 2, Activity 5.\n",
      "  - Removed 0 rows for Subject 8, Activity 11, Trials 2 & 3.\n",
      "\n",
      "Processing data for each sensor client...\n",
      "  - Client 0: Ankle_IMU\n",
      "  - Client 1: Pocket_IMU\n",
      "  - Client 2: Belt_IMU\n",
      "  - Client 3: Neck_IMU\n",
      "  - Client 4: Wrist_IMU\n",
      "\n",
      "Data loaded successfully for all sensor clients.\n",
      "{'Ankle_IMU': ['AnkleAccelerometer_x-axis (g)', 'AnkleAccelerometer_y-axis (g)', 'AnkleAccelerometer_z-axis (g)', 'AnkleAngularVelocity_x-axis (deg/s)', 'AnkleAngularVelocity_y-axis (deg/s)', 'AnkleAngularVelocity_z-axis (deg/s)', 'AnkleLuminosity_illuminance (lx)'], 'Pocket_IMU': ['RightPocketAccelerometer_x-axis (g)', 'RightPocketAccelerometer_y-axis (g)', 'RightPocketAccelerometer_z-axis (g)', 'RightPocketAngularVelocity_x-axis (deg/s)', 'RightPocketAngularVelocity_y-axis (deg/s)', 'RightPocketAngularVelocity_z-axis (deg/s)', 'RightPocketLuminosity_illuminance (lx)'], 'Belt_IMU': ['BeltAccelerometer_x-axis (g)', 'BeltAccelerometer_y-axis (g)', 'BeltAccelerometer_z-axis (g)', 'BeltAngularVelocity_x-axis (deg/s)', 'BeltAngularVelocity_y-axis (deg/s)', 'BeltAngularVelocity_z-axis (deg/s)', 'BeltLuminosity_illuminance (lx)'], 'Neck_IMU': ['NeckAccelerometer_x-axis (g)', 'NeckAccelerometer_y-axis (g)', 'NeckAccelerometer_z-axis (g)', 'NeckAngularVelocity_x-axis (deg/s)', 'NeckAngularVelocity_y-axis (deg/s)', 'NeckAngularVelocity_z-axis (deg/s)', 'NeckLuminosity_illuminance (lx)'], 'Wrist_IMU': ['WristAccelerometer_x-axis (g)', 'WristAccelerometer_y-axis (g)', 'WristAccelerometer_z-axis (g)', 'WristAngularVelocity_x-axis (deg/s)', 'WristAngularVelocity_y-axis (deg/s)', 'WristAngularVelocity_z-axis (deg/s)', 'WristLuminosity_illuminance (lx)']}\n",
      "\n",
      "Data for Client 0 (Ankle_IMU):\n",
      "  - X_train shape: (189957, 7)\n",
      "  - Y_train shape: torch.Size([189957, 11])\n",
      "  - X_test shape:  (68157, 7)\n",
      "  - Y_test shape:  torch.Size([68157, 11])\n",
      "\n",
      "Data for Client 1 (Pocket_IMU):\n",
      "  - X_train shape: (189957, 7)\n",
      "  - Y_train shape: torch.Size([189957, 11])\n",
      "  - X_test shape:  (68157, 7)\n",
      "  - Y_test shape:  torch.Size([68157, 11])\n",
      "\n",
      "Data for Client 2 (Belt_IMU):\n",
      "  - X_train shape: (189957, 7)\n",
      "  - Y_train shape: torch.Size([189957, 11])\n",
      "  - X_test shape:  (68157, 7)\n",
      "  - Y_test shape:  torch.Size([68157, 11])\n",
      "\n",
      "Data for Client 3 (Neck_IMU):\n",
      "  - X_train shape: (189957, 7)\n",
      "  - Y_train shape: torch.Size([189957, 11])\n",
      "  - X_test shape:  (68157, 7)\n",
      "  - Y_test shape:  torch.Size([68157, 11])\n",
      "\n",
      "Data for Client 4 (Wrist_IMU):\n",
      "  - X_train shape: (189957, 7)\n",
      "  - Y_train shape: torch.Size([189957, 11])\n",
      "  - X_test shape:  (68157, 7)\n",
      "  - Y_test shape:  torch.Size([68157, 11])\n",
      "\n",
      "===== STARTING NEW EXPERIMENT: Model=SensorOnlyModel, Selection=pareto =====\n",
      "Initializing model and server for 5 sensor clients...\n",
      "--- Round 1/10 ---\n",
      "Client 0 - Train Acc: 73.19%, Val Acc: 46.12%\n",
      "Client 1 - Train Acc: 76.27%, Val Acc: 49.69%\n",
      "Client 2 - Train Acc: 78.71%, Val Acc: 17.14%\n",
      "Client 3 - Train Acc: 72.49%, Val Acc: 41.49%\n",
      "Client 4 - Train Acc: 70.34%, Val Acc: 55.74%\n",
      "=== Pareto Optimization: Start ===\n",
      "Input rf_loss: ['0.89', '0.89', '0.69', '1.00', '0.99']\n",
      "Input rf_acc_train: ['0.93', '0.97', '1.00', '0.92', '0.89']\n",
      "Input rf_acc_val: ['0.83', '0.89', '0.31', '0.74', '1.00']\n",
      "Input rf_acc_global: ['0.04', '0.28', '-0.38', '0.23', '0.38']\n",
      "Input p_loss: ['0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Input p_bias: ['0.37', '0.28', '0.23', '0.21', '0.36']\n",
      "Number of clients to select: 3\n",
      "Converted all inputs to numpy arrays.\n",
      "Constructed data matrix for Pareto: shape=(5, 6)\n",
      "Pareto front client indices: [0, 1, 2, 3, 4]\n",
      "More Pareto clients than needed. Randomly selected: [3, 4, 0]\n",
      "=== Pareto Optimization: End ===\n",
      "Selected clients for aggregation: [3, 4, 0]\n",
      "Round 1 Global Model - Accuracy: 47.60%, Loss: 2.0832\n",
      "\n",
      "New best model found! Saving model...\n",
      "--- Round 2/10 ---\n",
      "Client 0 - Train Acc: 75.16%, Val Acc: 41.21%\n"
     ]
    }
   ],
   "source": [
    "# --- Define Experimental Scenarios and Hyperparameters ---\n",
    "model_name = 'SensorOnlyModel' # Simplified model name\n",
    "svmethods = {'pareto', '5RF', 'random'}\n",
    "svmethods = {'pareto'}\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "max_acc = 1\n",
    "epoch = 10\n",
    "epoch_size = 64\n",
    "total_client = 5 # UPDATED: Now we have 5 sensor clients\n",
    "num_clients = 3 # Number of clients to select per round\n",
    "local_epoch_per_round = 3\n",
    "round_early_stop = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Define the path to your single CSV file\n",
    "file_path = '/home/syed/PhD/UP-Fall-FL/dataset/Sensor + Image/sensor.csv'\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Load data using the new function\n",
    "    X_train_csv_scaled_splits, X_test_csv_scaled_splits, \\\n",
    "    Y_train_csv_splits, Y_test_csv_splits, \\\n",
    "    sensor_clients = loadSensorClientsData_from_csv(file_path)\n",
    "\n",
    "    print(\"\\nData loaded successfully for all sensor clients.\")\n",
    "    # You can now access the data for each client using its index (0 to 5)\n",
    "    print(sensor_clients)\n",
    "    for client_index, (client_name, columns) in enumerate(sensor_clients.items()):\n",
    "        print(f\"\\nData for Client {client_index} ({client_name}):\")\n",
    "        print(f\"  - X_train shape: {X_train_csv_scaled_splits[client_index].shape}\")\n",
    "        print(f\"  - Y_train shape: {Y_train_csv_splits[client_index].shape}\")\n",
    "        print(f\"  - X_test shape:  {X_test_csv_scaled_splits[client_index].shape}\")\n",
    "        print(f\"  - Y_test shape:  {Y_test_csv_splits[client_index].shape}\")\n",
    "\n",
    "    # Loop through each client selection method\n",
    "    for svmethod in svmethods:\n",
    "        print(f\"\\n===== STARTING NEW EXPERIMENT: Model={model_name}, Selection={svmethod} =====\")\n",
    "        # Call the training function with the simplified arguments\n",
    "        trainValModelCSVIMG(model_name, svmethod, total_client, num_clients, epoch, max_acc, epoch_size, local_epoch_per_round, round_early_stop,\n",
    "                        X_train_csv_scaled_splits, X_test_csv_scaled_splits,\n",
    "                        Y_train_csv_splits, Y_test_csv_splits, sensor_clients)\n",
    "\n",
    "# This makes the script runnable\n",
    "if __name__ == \"__main__\":\n",
    "    main()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921306f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flwr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
