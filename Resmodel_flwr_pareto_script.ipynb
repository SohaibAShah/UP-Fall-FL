{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0c3a569",
   "metadata": {},
   "source": [
    "Let's convert the entire script to use Flower, a popular framework for federated learning. Flower will handle all the complex server-client communication, so our code will become much simpler and more organized.\n",
    "\n",
    "We'll follow the same step-by-step process, keeping your original model, data loading functions, and variable names so you can easily see what's changed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0221b1e3",
   "metadata": {},
   "source": [
    "## Step 1: The Foundation (Imports and Setup)\n",
    "Every Python script starts with importing the necessary libraries and setting up the environment. This is like laying the foundation for a house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "696a41f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import OrderedDict\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "from flwr.common import Context # <-- ADD THIS LINE\n",
    "\n",
    "\n",
    "# --- Set Device ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729b56c2",
   "metadata": {},
   "source": [
    "### Define dataset loader\n",
    "\n",
    "PyTorch uses a Dataset object to handle data loading. Since our model will take three different kinds of input (sensor data, image 1, and image 2), we need to create a special class that tells PyTorch how to retrieve one sample of each, along with its corresponding label.\n",
    "\n",
    "This class will have three essential methods:\n",
    "\n",
    "__init__: Initializes the dataset by storing our feature and label arrays.\n",
    "\n",
    "__len__: Returns the total number of samples in the dataset.\n",
    "\n",
    "__getitem__: Fetches a single data sample at a given index.\n",
    "\n",
    "Here is the code for it. Add this to your script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ebd8185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset loader\n",
    "class CustomDatasetRes(Dataset):\n",
    "    def __init__(self, features1, features2, features3, labels):\n",
    "        self.features1 = features1\n",
    "        self.features2 = features2\n",
    "        self.features3 = features3\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features1)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.features1[index], self.features2[index], self.features3[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03702557",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "Next, we'll add a few helper functions. These functions will perform common tasks that we'll need later, like displaying results, scaling data, and ensuring our experiments are reproducible.\n",
    "\n",
    "1. display_result\n",
    "\n",
    "This function takes the true labels (y_test) and the model's predicted labels (y_pred) and prints out standard performance metrics like accuracy, precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e6414e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_result(y_test, y_pred):\n",
    "    print('Accuracy score : ', accuracy_score(y_test, y_pred))\n",
    "    print('Precision score : ', precision_score(y_test, y_pred, average='weighted'))\n",
    "    print('Recall score : ', recall_score(y_test, y_pred, average='weighted'))\n",
    "    print('F1 score : ', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75a5531",
   "metadata": {},
   "source": [
    "2. scaled_data\n",
    "\n",
    "This function uses Scikit-learn's StandardScaler to normalize the sensor (CSV) data. Scaling is crucial because it ensures that features with larger value ranges don't dominate the learning process. Notice there are two functions with the same name in the original code. In Python, the last definition of a function is the one that gets used. We will add both for completeness, but just know that the first one is effectively overwritten by the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adc0678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "def scaled_data(X_train):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    return X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d51f72",
   "metadata": {},
   "source": [
    "3. set_seed\n",
    "\n",
    "This is a very important function for reproducibility. Machine learning involves a lot of randomness (e.g., initializing model weights, shuffling data). By setting a \"seed,\" we ensure that the sequence of random numbers is the same every time we run the code, which means we'll get the exact same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93f4630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=0):\n",
    "    # Sets the environment variable for Python's hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    # Sets the seed for NumPy's random number generator\n",
    "    np.random.seed(seed)\n",
    "    # Sets the seed for Python's built-in random module\n",
    "    random.seed(seed)\n",
    "    # Sets the seed for PyTorch's random number generator\n",
    "    torch.manual_seed(seed)\n",
    "    # If using a GPU, sets the seed for all CUDA devices\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
    "    # Ensures deterministic behavior in cuDNN (CUDA Deep Neural Network library)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdf1683",
   "metadata": {},
   "source": [
    "### loading and preprocessing the data.\n",
    "\n",
    "The function loadClientsData is designed for a federated learning scenario. It reads data from separate files for each participant (or \"client\"), cleans it, aligns the different data types (sensor vs. image), and splits it into training and testing sets for each client.\n",
    "\n",
    "Because this function is quite long, we'll build it in a few parts.\n",
    "\n",
    "#### Part 1: Initializing and Processing Training Data\n",
    "First, we'll define the function, list the subject IDs we want to load, and create empty dictionaries to store each client's data. Then, we'll start a loop to process each subject one by one. Inside the loop, we'll begin by loading and cleaning the training data.\n",
    "\n",
    "This involves:\n",
    "\n",
    "Reading the sensor data from a CSV file.\n",
    "\n",
    "Removing rows with missing values and any duplicate rows.\n",
    "\n",
    "Dropping columns that we don't need (like the 'Infrared' sensor readings).\n",
    "\n",
    "Loading the corresponding image, label, and timestamp data from .npy files.\n",
    "\n",
    "#### Part 2: Aligning and Preparing Training Data\n",
    "After loading the raw data, we face a common problem: the datasets don't perfectly match. Because we dropped rows with missing values from the sensor (CSV) data, there are now timestamps in our image data that no longer have a corresponding entry in the sensor data.\n",
    "\n",
    "We need to align them by removing the image samples that don't have a matching sensor reading.\n",
    "\n",
    "After alignment, we'll prepare the data for the model:\n",
    "\n",
    "Set the seed for reproducibility.\n",
    "\n",
    "Separate features from labels.\n",
    "\n",
    "One-hot encode the labels, converting them into a format suitable for the model's output layer (e.g., class 3 becomes [0, 0, 0, 1, 0, ...]).\n",
    "\n",
    "Scale the numeric sensor data and the image pixel values.\n",
    "\n",
    "Reshape the images to the format expected by the convolutional layers.\n",
    "\n",
    "#### Part 3: Processing the Test Data and Finalizing the Function\n",
    "The logic here is identical to what we just did for the training data:\n",
    "\n",
    "Load the test sensor data (_test.csv) and test image data (_test.npy).\n",
    "\n",
    "Clean the sensor data by removing missing values and unnecessary columns.\n",
    "\n",
    "Align the test image data with the cleaned test sensor data.\n",
    "\n",
    "Prepare the aligned test data (one-hot encode labels, scale features, reshape images).\n",
    "\n",
    "Store all the processed training and test arrays into our dictionaries.\n",
    "\n",
    "Increment the clint_index and repeat the process for the next subject.\n",
    "\n",
    "After the loop finishes, the function returns all the dictionaries containing the data for every client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81f6095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadClientsData():\n",
    "    #subs = [1, 3, 4, 7, 10, 11, 12, 13, 14, 15, 16, 17]\n",
    "    subs = [1, 4, 7, 11, 12, 14, 15, 17]\n",
    "    X_train_csv_scaled_splits = {}\n",
    "    X_test_csv_scaled_splits = {}\n",
    "    Y_train_csv_splits = {}\n",
    "    Y_test_csv_splits = {}\n",
    "    X_train_1_scaled_splits = {}\n",
    "    X_test_1_scaled_splits = {}\n",
    "    Y_train_1_splits = {}\n",
    "    Y_test_1_splits = {}\n",
    "    X_train_2_scaled_splits = {}\n",
    "    X_test_2_scaled_splits = {}\n",
    "    Y_train_2_splits = {}\n",
    "    Y_test_2_splits = {}\n",
    "    clint_index = 0\n",
    "    for sub_ in subs:\n",
    "        # --- Load and clean TRAINING sensor data (CSV) ---\n",
    "        SUB_train = pd.read_csv('./dataset/Sensor + Image/{}_sensor_train.csv'.format(sub_), skiprows=1)\n",
    "        SUB_train.head()\n",
    "        \n",
    "        SUB_train.isnull().sum()\n",
    "        NA_cols = SUB_train.columns[SUB_train.isnull().any()]\n",
    "        SUB_train.dropna(inplace=True)\n",
    "        SUB_train.drop_duplicates(inplace=True)\n",
    "        \n",
    "        times_train = SUB_train['Time']\n",
    "        list_DROP = ['Infrared 1',\n",
    "                     'Infrared 2',\n",
    "                     'Infrared 3',\n",
    "                     'Infrared 4',\n",
    "                     'Infrared 5',\n",
    "                     'Infrared 6']\n",
    "        SUB_train.drop(list_DROP, axis=1, inplace=True)\n",
    "        SUB_train.drop(NA_cols, axis=1, inplace=True)  # drop NAN COLS\n",
    "\n",
    "        SUB_train.set_index('Time', inplace=True)\n",
    "        SUB_train.head()\n",
    "\n",
    "        # --- Load TRAINING image data from both cameras ---\n",
    "        cam = '1'\n",
    "        image_train = './dataset/Sensor + Image' + '/' + '{}_image_1_train.npy'.format(sub_)\n",
    "        name_train = './dataset/Sensor + Image' + '/' + '{}_name_1_train.npy'.format(sub_)\n",
    "        label_train = './dataset/Sensor + Image' + '/' + '{}_label_1_train.npy'.format(sub_)\n",
    "\n",
    "        img_1_train = np.load(image_train)\n",
    "        label_1_train = np.load(label_train)\n",
    "        name_1_train = np.load(name_train)\n",
    "\n",
    "        cam = '2'\n",
    "        image_train = './dataset/Sensor + Image' + '/' + '{}_image_2_train.npy'.format(sub_)\n",
    "        name_train = './dataset/Sensor + Image' + '/' + '{}_name_2_train.npy'.format(sub_)\n",
    "        label_train = './dataset/Sensor + Image' + '/' + '{}_label_2_train.npy'.format(sub_)\n",
    "\n",
    "        img_2_train = np.load(image_train)\n",
    "        label_2_train = np.load(label_train)\n",
    "        name_2_train = np.load(name_train)\n",
    "\n",
    "        # --- Align the training data by removing samples not present in the cleaned CSV ---\n",
    "        redundant_1 = list(set(name_1_train) - set(times_train))\n",
    "        redundant_2 = list(set(name_2_train) - set(times_train))\n",
    "        \n",
    "        ind = np.arange(0, len(img_1_train))\n",
    "\n",
    "        red_in1 = ind[np.isin(name_1_train, redundant_1)]\n",
    "        name_1_train = np.delete(name_1_train, red_in1)\n",
    "        img_1_train = np.delete(img_1_train, red_in1, axis=0)\n",
    "        label_1_train = np.delete(label_1_train, red_in1)\n",
    "\n",
    "        red_in2 = ind[np.isin(name_2_train, redundant_2)]\n",
    "        name_2_train = np.delete(name_2_train, red_in2)\n",
    "        img_2_train = np.delete(img_2_train, red_in2, axis=0)\n",
    "        label_2_train = np.delete(label_2_train, red_in2)\n",
    "        \n",
    "        # --- Prepare the final aligned training data ---\n",
    "        data_train = SUB_train.loc[name_1_train].values\n",
    "\n",
    "        set_seed()\n",
    "        X_csv_train, y_csv_train = data_train[:, :-1], data_train[:, -1]\n",
    "        \n",
    "        # Remap label 20 to 0 for consistency\n",
    "        y_csv_train = np.where(y_csv_train == 20, 0, y_csv_train)\n",
    "        label_1_train = np.where(label_1_train == 20, 0, label_1_train)\n",
    "        label_2_train = np.where(label_2_train == 20, 0, label_2_train)\n",
    "\n",
    "        # One-hot encode the labels for PyTorch\n",
    "        Y_csv_train = torch.nn.functional.one_hot(torch.from_numpy(y_csv_train).long(), 12).float()\n",
    "        Y_train_1 = torch.nn.functional.one_hot(torch.from_numpy(label_1_train).long(), 12).float()\n",
    "        Y_train_2 = torch.nn.functional.one_hot(torch.from_numpy(label_2_train).long(), 12).float()\n",
    "\n",
    "        \n",
    "\n",
    "        X_train_1 = img_1_train\n",
    "        y_train_1 = label_1_train\n",
    "        \n",
    "        X_train_2 = img_2_train\n",
    "        y_train_2 = label_2_train\n",
    "\n",
    "        # Reshape images to (samples, height, width, channels)\n",
    "        shape1, shape2 = 32, 32\n",
    "        X_train_1 = X_train_1.reshape(X_train_1.shape[0], shape1, shape2, 1)\n",
    "        X_train_2 = X_train_2.reshape(X_train_2.shape[0], shape1, shape2, 1)\n",
    "\n",
    "        # Scale image pixel values to be between 0 and 1\n",
    "        X_train_1_scaled = X_train_1 / 255.0\n",
    "        X_train_2_scaled = X_train_2 / 255.0\n",
    "\n",
    "        # --- Load and clean TEST sensor data (CSV) ---\n",
    "        SUB_test = pd.read_csv('./dataset/Sensor + Image/{}_sensor_test.csv'.format(sub_), skiprows=1)\n",
    "        SUB_test.head()\n",
    "        \n",
    "        SUB_test.isnull().sum()\n",
    "        NA_cols = SUB_test.columns[SUB_test.isnull().any()]\n",
    "        SUB_test.dropna(inplace=True)\n",
    "        SUB_test.drop_duplicates(inplace=True)\n",
    "\n",
    "        times_test = SUB_test['Time']\n",
    "        SUB_test.drop(list_DROP, axis=1, inplace=True)\n",
    "        SUB_test.drop(NA_cols, axis=1, inplace=True)\n",
    "\n",
    "        SUB_test.set_index('Time', inplace=True)\n",
    "        SUB_test.head()\n",
    "\n",
    "        # --- Load TEST image data from both cameras ---\n",
    "        image_test = './dataset/Sensor + Image' + '/' + '{}_image_1_test.npy'.format(sub_)\n",
    "        name_test = './dataset/Sensor + Image' + '/' + '{}_name_1_test.npy'.format(sub_)\n",
    "        label_test = './dataset/Sensor + Image' + '/' + '{}_label_1_test.npy'.format(sub_)\n",
    "        img_1_test = np.load(image_test)\n",
    "        label_1_test = np.load(label_test)\n",
    "        name_1_test = np.load(name_test)\n",
    "\n",
    "        image_test = './dataset/Sensor + Image' + '/' + '{}_image_2_test.npy'.format(sub_)\n",
    "        name_test = './dataset/Sensor + Image' + '/' + '{}_name_2_test.npy'.format(sub_)\n",
    "        label_test = './dataset/Sensor + Image' + '/' + '{}_label_2_test.npy'.format(sub_)\n",
    "        img_2_test = np.load(image_test)\n",
    "        label_2_test = np.load(label_test)\n",
    "        name_2_test = np.load(name_test)\n",
    "\n",
    "        # --- Align the test data ---\n",
    "        redundant_1 = list(set(name_1_test) - set(times_test))\n",
    "        redundant_2 = list(set(name_2_test) - set(times_test))\n",
    "        \n",
    "        ind = np.arange(0, len(img_1_test))\n",
    "\n",
    "        red_in1 = ind[np.isin(name_1_test, redundant_1)]\n",
    "        name_1_test = np.delete(name_1_test, red_in1)\n",
    "        img_1_test = np.delete(img_1_test, red_in1, axis=0)\n",
    "        label_1_test = np.delete(label_1_test, red_in1)\n",
    "\n",
    "        red_in2 = ind[np.isin(name_2_test, redundant_2)]\n",
    "        name_2_test = np.delete(name_2_test, red_in2)\n",
    "        img_2_test = np.delete(img_2_test, red_in2, axis=0)\n",
    "        label_2_test = np.delete(label_2_test, red_in2)\n",
    "\n",
    "        # --- Prepare the final aligned test data ---\n",
    "        data_test = SUB_test.loc[name_1_test].values\n",
    "\n",
    "        set_seed()\n",
    "        X_csv_test, y_csv_test = data_test[:, :-1], data_test[:, -1]\n",
    "        y_csv_test = np.where(y_csv_test == 20, 0, y_csv_test)\n",
    "        label_1_test = np.where(label_1_test == 20, 0, label_1_test)\n",
    "        label_2_test = np.where(label_2_test == 20, 0, label_2_test)\n",
    "\n",
    "        Y_csv_test = torch.nn.functional.one_hot(torch.from_numpy(y_csv_test).long(), 12).float()\n",
    "        X_csv_train_scaled, X_csv_test_scaled = scale_data(X_csv_train, X_csv_test)\n",
    "\n",
    "        X_test_1 = img_1_test\n",
    "        y_test_1 = label_1_test\n",
    "        Y_test_1 = torch.nn.functional.one_hot(torch.from_numpy(y_test_1).long(), 12).float()\n",
    "\n",
    "        X_test_2 = img_2_test\n",
    "        y_test_2 = label_2_test\n",
    "        Y_test_2 = torch.nn.functional.one_hot(torch.from_numpy(y_test_2).long(), 12).float()\n",
    "\n",
    "        X_test_1 = X_test_1.reshape(X_test_1.shape[0], shape1, shape2, 1)\n",
    "        X_test_2 = X_test_2.reshape(X_test_2.shape[0], shape1, shape2, 1)\n",
    "\n",
    "        X_test_1_scaled = X_test_1 / 255.0\n",
    "        X_test_2_scaled = X_test_2 / 255.0\n",
    "\n",
    "        # --- Store all processed data for the current client ---\n",
    "        X_train_csv_scaled_splits[clint_index] = X_csv_train_scaled\n",
    "        X_test_csv_scaled_splits[clint_index] = X_csv_test_scaled\n",
    "        Y_train_csv_splits[clint_index] = Y_csv_train\n",
    "        Y_test_csv_splits[clint_index] = Y_csv_test\n",
    "        X_train_1_scaled_splits[clint_index] = X_train_1_scaled\n",
    "        X_test_1_scaled_splits[clint_index] = X_test_1_scaled\n",
    "        Y_train_1_splits[clint_index] = Y_train_1\n",
    "        Y_test_1_splits[clint_index] = Y_test_1\n",
    "        X_train_2_scaled_splits[clint_index] = X_train_2_scaled # This line had a bug in the original code\n",
    "        X_test_2_scaled_splits[clint_index] = X_test_2_scaled\n",
    "        Y_train_2_splits[clint_index] = Y_train_2\n",
    "        Y_test_2_splits[clint_index] = Y_test_2\n",
    "        clint_index += 1\n",
    "        \n",
    "    # --- After loop, return all dictionaries ---\n",
    "    return X_train_csv_scaled_splits,X_test_csv_scaled_splits, Y_train_csv_splits,Y_test_csv_splits,X_train_1_scaled_splits,X_test_1_scaled_splits,Y_train_1_splits,Y_test_1_splits,X_train_2_scaled_splits,X_test_2_scaled_splits,Y_train_2_splits,Y_test_2_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9e1b50",
   "metadata": {},
   "source": [
    "## Step 2: Client Selection\n",
    "\n",
    "We're making great progress. We've handled all the data loading and preparation. Now, we'll add the functions that form the \"intelligence\" of our federated learning system: client selection.\n",
    "\n",
    "Instead of blindly averaging updates from every client in every round, these methods evaluate each client's performance and contribution. This allows the server to select the most promising or reliable clients to participate in the global model update, potentially leading to faster convergence and a more robust final model.\n",
    "\n",
    "We'll add a series of functions, each calculating a specific metric to judge the clients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5173b0f8",
   "metadata": {},
   "source": [
    "### Client Evaluation Metrics\n",
    "Add all the following functions to your script. Each one calculates a different score based on a client's performance.\n",
    "\n",
    "1. Relative Loss Reduction (RF_loss)\n",
    "\n",
    "This measures how much a client's training loss has dropped from the beginning to the end of a local training round, relative to the client with the biggest drop. A higher score means the client is learning effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f48d0a",
   "metadata": {},
   "source": [
    "2. Relative Training Accuracy (RF_ACC_Train)\n",
    "\n",
    "This measures a client's local training accuracy relative to the client with the highest accuracy. It's a straightforward measure of performance on local data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e977c2",
   "metadata": {},
   "source": [
    "3. Global Validation Accuracy (RF_ACC_Global)\n",
    "\n",
    "This is a more sophisticated metric. It rewards clients for high accuracy on a global test set but penalizes them if their global accuracy is much worse than their local training accuracy (which is a sign of overfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f26f9bf",
   "metadata": {},
   "source": [
    "4. Loss Outliers (P_loss)\n",
    "\n",
    "This function flags clients that are potential negative contributors. If a client's final training loss is significantly higher than the average loss of all clients, it gets a high penalty score. Otherwise, its penalty is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef96a2ac",
   "metadata": {},
   "source": [
    "5. Performance Bias (P_bias)\n",
    "\n",
    "This metric calculates the gap between a client's performance on its own validation data versus its performance on the global validation data. A large gap might indicate that the client's local data is not representative of the overall data distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62f94b9",
   "metadata": {},
   "source": [
    "##### Replace above Metric Helper Functions by below updated version that use disctionaries instead of Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6a847f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Replace ALL old metric helpers with these dictionary-based versions ---\n",
    "\n",
    "def calculate_relative_loss_reduction_as_list(client_losses):\n",
    "    \"\"\"Calculates RF_loss. Returns a DICTIONARY {cid: score}.\"\"\"\n",
    "    loss_reductions = {}\n",
    "    for cid, losses in client_losses.items():\n",
    "        if losses and len(losses) >= 2:\n",
    "            loss_reductions[cid] = losses[0] - losses[-1]\n",
    "\n",
    "    if not loss_reductions: return {cid: 0.0 for cid in client_losses.keys()}\n",
    "    max_loss_reduction = max(loss_reductions.values())\n",
    "    if max_loss_reduction == 0: return {cid: 0.0 for cid in client_losses.keys()}\n",
    "    \n",
    "    return {cid: loss_reductions.get(cid, 0.0) / max_loss_reduction for cid in client_losses.keys()}\n",
    "\n",
    "def calculate_relative_train_accuracy(client_acc):\n",
    "    \"\"\"Calculates RF_ACC_Train. Returns a DICTIONARY {cid: score}.\"\"\"\n",
    "    if not client_acc: return {}\n",
    "    max_acc = max(client_acc.values())\n",
    "    if max_acc == 0: return {cid: 0.0 for cid in client_acc.keys()}\n",
    "    return {cid: acc / max_acc for cid, acc in client_acc.items()}\n",
    "\n",
    "def calculate_global_validation_accuracy(train_acc, global_acc):\n",
    "    \"\"\"Calculates RF_ACC_Global. Returns a DICTIONARY {cid: score}.\"\"\"\n",
    "    if not train_acc or not global_acc: return {}\n",
    "    max_global_acc = max(global_acc.values()) if global_acc else 0\n",
    "    if max_global_acc == 0: max_global_acc = 1.0\n",
    "\n",
    "    global_train_diff = {cid: global_acc.get(cid, 0) - train_acc.get(cid, 0) for cid in train_acc.keys()}\n",
    "    max_global_train_diff = max(global_train_diff.values()) if global_train_diff else 0\n",
    "    if max_global_train_diff == 0: max_global_train_diff = 1.0\n",
    "    \n",
    "    return {cid: (global_acc.get(cid, 0) / max_global_acc) - (diff / max_global_train_diff) for cid, diff in global_train_diff.items()}\n",
    "\n",
    "def calculate_loss_outliers(client_losses, lambda_loss=1.5):\n",
    "    \"\"\"Calculates P_loss. Returns a DICTIONARY {cid: score}.\"\"\"\n",
    "    final_losses = {cid: losses[-1] for cid, losses in client_losses.items() if losses}\n",
    "    if not final_losses: return {cid: 0.0 for cid in client_losses.keys()}\n",
    "\n",
    "    loss_values = np.array(list(final_losses.values()))\n",
    "    mean_loss, std_loss = np.mean(loss_values), np.std(loss_values)\n",
    "    threshold = mean_loss + lambda_loss * std_loss\n",
    "    max_loss = np.max(loss_values)\n",
    "    if max_loss == 0: return {cid: 0.0 for cid in client_losses.keys()}\n",
    "    \n",
    "    all_client_scores = {}\n",
    "    for cid in client_losses.keys():\n",
    "        final_loss = final_losses.get(cid, 0.0)\n",
    "        score = final_loss / max_loss if final_loss > threshold else 0.0\n",
    "        all_client_scores[cid] = score\n",
    "    return all_client_scores\n",
    "\n",
    "def calculate_performance_bias(val_acc, global_acc):\n",
    "    \"\"\"Calculates P_bias. Returns a DICTIONARY {cid: score}.\"\"\"\n",
    "    if not val_acc: return {}\n",
    "    \n",
    "    bias_dict = {}\n",
    "    for cid, val in val_acc.items():\n",
    "        global_val = global_acc.get(cid, 0.0)\n",
    "        max_val = max(val, global_val)\n",
    "        bias = 0.0 if max_val == 0 else abs(val - global_val) / max_val\n",
    "        bias_dict[cid] = bias\n",
    "    return bias_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dfd596",
   "metadata": {},
   "source": [
    "Excellent. Now that we have the functions to score each client, we need the final step: the algorithms that use these scores to select which clients will participate in a given round."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626cecd1",
   "metadata": {},
   "source": [
    "### Client Selection Algorithms\n",
    "1. Pareto Optimization\n",
    "\n",
    "This is a powerful technique used when you have multiple, often conflicting, objectives. Instead of combining all metrics into one score, it tries to find a set of clients that represent the best possible trade-offs.\n",
    "\n",
    "A client is considered \"Pareto optimal\" if no other client is better than it across all metrics. The algorithm first finds this set of optimal clients.\n",
    "\n",
    "If there are more optimal clients than needed, it selects a random subset.\n",
    "\n",
    "If there are fewer, it fills the remaining spots by picking the clients with the best-combined performance score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25f90e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pareto_optimization(rf_loss, rf_acc_train, rf_acc_val, rf_acc_global, p_loss, p_bias, client_num, client_ids):\n",
    "    \"\"\"Implements Pareto optimization to select clients.\"\"\"\n",
    "    # Convert metric dicts to a numpy array, ensuring a consistent order via client_ids\n",
    "    data_points = [\n",
    "        np.array([rf_loss.get(cid, 0), rf_acc_train.get(cid, 0), rf_acc_val.get(cid, 0),\n",
    "                  rf_acc_global.get(cid, 0), -p_loss.get(cid, 0), -p_bias.get(cid, 0)])\n",
    "        for cid in client_ids\n",
    "    ]\n",
    "    data = np.array(data_points)\n",
    "\n",
    "    def is_dominated(point, others):\n",
    "        \"\"\"Checks if a point is dominated by any other point in the set.\"\"\"\n",
    "        return any(np.all(other >= point) and np.any(other > point) for other in others)\n",
    "\n",
    "    pareto_indices = [i for i, point in enumerate(data) if not is_dominated(point, np.delete(data, i, axis=0))]\n",
    "    # Map indices back to the original string client IDs\n",
    "    pareto_cids = [client_ids[i] for i in pareto_indices]\n",
    "\n",
    "    if len(pareto_cids) >= client_num:\n",
    "        return random.sample(pareto_cids, client_num)\n",
    "    \n",
    "    # CORRECTED: Use a dictionary comprehension with string CIDs\n",
    "    pareto_scores = {cid: 0.4 * rf_loss.get(cid, 0) + 0.6 * rf_acc_global.get(cid, 0) for cid in client_ids}\n",
    "    \n",
    "    # Sort the original client IDs based on their scores\n",
    "    sorted_cids = sorted(client_ids, key=lambda cid: pareto_scores.get(cid, 0), reverse=True)\n",
    "    \n",
    "    selected_clients = set(pareto_cids)\n",
    "    for cid in sorted_cids:\n",
    "        if len(selected_clients) >= client_num:\n",
    "            break\n",
    "        selected_clients.add(cid)\n",
    "        \n",
    "    # CORRECTED: Return a list of strings\n",
    "    return list(selected_clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ebf65c",
   "metadata": {},
   "source": [
    "2. Weighted Sum Method (5RF)\n",
    "\n",
    "This is a more straightforward approach. It calculates a single comprehensive score for each client by taking a weighted sum of all the metrics. Clients with the highest final scores are selected. The weights (0.2, 0.1, 0.3, etc.) determine the importance of each metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb04b0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee125dce",
   "metadata": {},
   "source": [
    "## Step 2: The AI's Brain (The Model Definition)\n",
    "We have the data pipeline and the client selection logic. Now it's time to build the brain of the operation: the neural network model itself.\n",
    "\n",
    "The model, ModelCSVIMG, is a multi-modal neural network. This means it's designed to accept and process multiple types of data at once. It has three distinct input branches:\n",
    "\n",
    "One for the numerical sensor (CSV) data.\n",
    "\n",
    "One for the images from camera 1.\n",
    "\n",
    "One for the images from camera 2.\n",
    "\n",
    "The features extracted from each branch are then combined (fused) and passed to a final set of layers that perform the classification. The original code contains a few versions of the architecture; we will use the final, most complex one.\n",
    "\n",
    "Add the complete model class to your script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "218bbd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCSVIMG(nn.Module):\n",
    "    def __init__(self, num_csv_features, img_shape1, img_shape2):\n",
    "        super(ModelCSVIMG, self).__init__()\n",
    "\n",
    "        # --- Branch 1: For processing numerical CSV data ---\n",
    "        self.csv_fc_1 = nn.Linear(num_csv_features, 2000)\n",
    "        self.csv_bn_1 = nn.BatchNorm1d(2000)\n",
    "        self.csv_fc_2 = nn.Linear(2000, 600)\n",
    "        self.csv_bn_2 = nn.BatchNorm1d(600)\n",
    "        self.csv_dropout = nn.Dropout(0.2)\n",
    "\n",
    "        # --- Branch 2: For processing images from Camera 1 (CNN) ---\n",
    "        self.img1_conv_1 = nn.Conv2d(in_channels=1, out_channels=18, kernel_size=3, stride=1, padding=1)\n",
    "        self.img1_batch_norm = nn.BatchNorm2d(18)\n",
    "        self.img1_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Flattened features from the CNN go into a fully connected layer\n",
    "        self.img1_fc1 = nn.Linear(18 * 16 * 16, 100)\n",
    "        self.img1_dropout = nn.Dropout(0.2)\n",
    "\n",
    "        # --- Branch 3: For processing images from Camera 2 (identical to Branch 2) ---\n",
    "        self.img2_conv = nn.Conv2d(in_channels=1, out_channels=18, kernel_size=3, stride=1, padding=1)\n",
    "        self.img2_batch_norm = nn.BatchNorm2d(18)\n",
    "        self.img2_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.img2_fc1 = nn.Linear(18 * 16 * 16, 100)\n",
    "        self.img2_dropout = nn.Dropout(0.2)\n",
    "\n",
    "        # --- Fusion and Final Classification Layers ---\n",
    "        # The input size is 600 (from CSV) + 100 (from Image 1) + 100 (from Image 2) = 800\n",
    "        self.fc1 = nn.Linear(800, 1200)\n",
    "        self.dr1 = nn.Dropout(0.2)\n",
    "        # A residual connection is used here: input to fc2 is the original 800 + output of fc1 (1200) = 2000\n",
    "        self.fc2 = nn.Linear(2000, 12) # 12 output classes\n",
    "\n",
    "    def forward(self, x_csv, x_img1, x_img2):\n",
    "        # --- Process CSV data ---\n",
    "        x_csv = F.relu(self.csv_bn_1(self.csv_fc_1(x_csv)))\n",
    "        x_csv = F.relu(self.csv_bn_2(self.csv_fc_2(x_csv)))\n",
    "        x_csv = self.csv_dropout(x_csv)\n",
    "\n",
    "        # --- Process Image 1 data ---\n",
    "        # Reshape image from (batch, height, width, channels) to (batch, channels, height, width)\n",
    "        x_img1 = x_img1.permute(0, 3, 1, 2)\n",
    "        x_img1 = F.relu(self.img1_conv_1(x_img1))\n",
    "        x_img1 = self.img1_batch_norm(x_img1)\n",
    "        x_img1 = self.img1_pool(x_img1)\n",
    "        x_img1 = x_img1.contiguous().view(x_img1.size(0), -1) # Flatten\n",
    "        x_img1 = F.relu(self.img1_fc1(x_img1))\n",
    "        x_img1 = self.img1_dropout(x_img1)\n",
    "\n",
    "        # --- Process Image 2 data ---\n",
    "        x_img2 = x_img2.permute(0, 3, 1, 2)\n",
    "        x_img2 = F.relu(self.img2_conv(x_img2))\n",
    "        x_img2 = self.img2_batch_norm(x_img2)\n",
    "        x_img2 = self.img2_pool(x_img2)\n",
    "        x_img2 = x_img2.contiguous().view(x_img2.size(0), -1) # Flatten\n",
    "        x_img2 = F.relu(self.img2_fc1(x_img2))\n",
    "        x_img2 = self.img2_dropout(x_img2)\n",
    "\n",
    "        # --- Fusion ---\n",
    "        x = torch.cat((x_csv, x_img1, x_img2), dim=1)\n",
    "        residual = x # Keep a copy for the residual connection\n",
    "        \n",
    "        # --- Final layers ---\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dr1(x)\n",
    "        # Concatenate the residual connection\n",
    "        x = torch.cat((residual, x), dim=1)\n",
    "        # Final output with softmax for classification\n",
    "        x = F.softmax(self.fc2(x), dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed243d7",
   "metadata": {},
   "source": [
    "## Step 3: Define Training and Testing Functions\n",
    "Instead of methods inside a Client class, we'll create standalone train and test functions. This makes the code cleaner. This logic is taken directly from your train_one_epoch and validate functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24327736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, epochs):\n",
    "    \"\"\"Train the model and return the list of losses.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "    net.train()\n",
    "    losses = []\n",
    "    for _ in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch in trainloader:\n",
    "            data1, data2, data3, target = batch\n",
    "            data1, data2, data3, target = data1.to(DEVICE).float(), data2.to(DEVICE).float(), data3.to(DEVICE).float(), target.to(DEVICE).float()\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(net(data1, data2, data3), target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        losses.append(epoch_loss / len(trainloader))\n",
    "    return losses # Return the history of losses\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Validate the model on the test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(testloader, \"Testing\"):\n",
    "            data1, data2, data3, target = batch\n",
    "            data1, data2, data3, target = data1.to(DEVICE).float(), data2.to(DEVICE).float(), data3.to(DEVICE).float(), target.to(DEVICE).float()\n",
    "            outputs = net(data1, data2, data3)\n",
    "            loss += criterion(outputs, target).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == torch.max(target, 1)[1]).sum().item()\n",
    "    accuracy = correct / total\n",
    "    return loss / len(testloader), accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e1123f",
   "metadata": {},
   "source": [
    "## Step 4: Create the Flower Client\n",
    "This is where Flower really comes in. We'll replace your custom Client class with a FlowerClient that inherits from Flower's NumPyClient. This class tells Flower how each client should handle parameters received from the server and how to perform local training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e0218cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return [val.cpu().numpy() for _, val in self.net.state_dict().items()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.net.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        self.net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        # NEW: Print when a client starts training\n",
    "        print(f\"✅ [Client {self.cid}] Starting training for round {config['server_round']}...\")\n",
    "\n",
    "        self.set_parameters(parameters)\n",
    "        \n",
    "        # Train and get the list of losses\n",
    "        losses = train(self.net, self.trainloader, epochs=3)\n",
    "        \n",
    "        # Also get the local validation accuracy\n",
    "        _, val_acc = test(self.net, self.valloader)\n",
    "\n",
    "        # NEW: Announce completion of training\n",
    "        print(f\"✅ [Client {self.cid}] Finished training.\")\n",
    "        \n",
    "        # Return parameters, dataset size, and our custom metrics dictionary\n",
    "        return self.get_parameters(config={}), len(self.trainloader.dataset), {\n",
    "            \"train_losses\": losses, \n",
    "            \"val_acc\": val_acc\n",
    "        }\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        # NEW: Print when a client starts evaluation\n",
    "        print(f\"[Client {self.cid}] Starting evaluation...\")\n",
    "\n",
    "        self.set_parameters(parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        \n",
    "        # NEW: Print the client's evaluation results\n",
    "        print(f\"✅ [Client {self.cid}] Evaluation results - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        return float(loss), len(self.valloader.dataset), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da725a3a",
   "metadata": {},
   "source": [
    "## Step 5: Create the ParetoStrategy\n",
    "Now for the main event. We create a new strategy class that collects all the client metrics and uses them to run your Pareto selection logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "424950c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParetoStrategy(fl.server.strategy.FedAvg):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.client_fit_metrics = {}\n",
    "        self.client_eval_metrics = {}\n",
    "\n",
    "        # NEW: Define a function to create the config for clients\n",
    "        def on_fit_config_fn(server_round: int):\n",
    "            \"\"\"Return a configuration dictionary for the clients.\"\"\"\n",
    "            config = {\"server_round\": server_round}\n",
    "            return config\n",
    "        \n",
    "        # NEW: Assign this function to the strategy\n",
    "        self.on_fit_config_fn = on_fit_config_fn\n",
    "\n",
    "    def aggregate_fit(self, server_round, results, failures):\n",
    "        for _, fit_res in results:\n",
    "            if fit_res.metrics:\n",
    "                self.client_fit_metrics[fit_res.client.cid] = fit_res.metrics\n",
    "        return super().aggregate_fit(server_round, results, failures)\n",
    "\n",
    "    def aggregate_evaluate(self, server_round, results, failures):\n",
    "        # NEW: Announce that the server has received evaluation results\n",
    "        print(f\"✅ --- Server received {len(results)} evaluation results in round {server_round} ---\")\n",
    "        for client, eval_res in results:\n",
    "            self.client_eval_metrics[client.cid] = {\"accuracy\": eval_res.metrics[\"accuracy\"]}\n",
    "        return super().aggregate_evaluate(server_round, results, failures)\n",
    "\n",
    "    def configure_fit(self, server_round, parameters, client_manager):\n",
    "        if server_round == 1:\n",
    "            print(\"--- Round 1: Selecting clients randomly ---\")\n",
    "            return super().configure_fit(server_round, parameters, client_manager)\n",
    "\n",
    "        all_cids = list(client_manager.clients.keys())\n",
    "        train_losses = {cid: self.client_fit_metrics.get(cid, {}).get(\"train_losses\", []) for cid in all_cids}\n",
    "        local_val_acc = {cid: self.client_fit_metrics.get(cid, {}).get(\"val_acc\", 0.0) for cid in all_cids}\n",
    "        local_train_acc_for_rf = local_val_acc\n",
    "        global_eval_acc = {cid: self.client_eval_metrics.get(cid, {}).get(\"accuracy\", 0.0) for cid in all_cids}\n",
    "        \n",
    "        rf_loss = calculate_relative_loss_reduction_as_list(train_losses)\n",
    "        rf_acc_train = calculate_relative_train_accuracy(local_train_acc_for_rf)\n",
    "        rf_acc_val = calculate_relative_train_accuracy(local_val_acc)\n",
    "        rf_acc_global = calculate_global_validation_accuracy(local_train_acc_for_rf, global_eval_acc)\n",
    "        p_loss = calculate_loss_outliers(train_losses)\n",
    "        p_bias = calculate_performance_bias(local_val_acc, global_eval_acc)\n",
    "        \n",
    "        num_to_select = int(self.fraction_fit * len(all_cids))\n",
    "        selected_cids = pareto_optimization(\n",
    "            rf_loss, rf_acc_train, rf_acc_val, rf_acc_global, p_loss, p_bias,\n",
    "            num_to_select, all_cids\n",
    "        )\n",
    "        \n",
    "        # NEW: Announce which clients were selected by the strategy\n",
    "        print(f\"✅ --- Pareto selection for round {server_round} chose clients: {selected_cids} ---\")\n",
    "\n",
    "        clients = [client_manager.clients[cid] for cid in selected_cids]\n",
    "        config = self.on_fit_config_fn(server_round)\n",
    "        return [(client, config) for client in clients]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee359c6b",
   "metadata": {},
   "source": [
    "## Step 5: The main Function - Bringing It All Together\n",
    "Finally, we rewrite the main function. This is where we will:\n",
    "\n",
    "Load all the client data just once.\n",
    "\n",
    "Define a client_fn. Flower uses this function to create clients on demand for the simulation.\n",
    "\n",
    "Define a server-side evaluation function (get_evaluate_fn) so the server can test the global model's performance on a held-out test set after each round.\n",
    "\n",
    "Configure and start the Flower simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619bbfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loading data for all clients...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=10, no round_timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data for 8 clients loaded successfully.\n",
      "✅ Starting Flower simulation with Pareto Strategy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 08:37:01,608\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0, 'node:172.30.170.62': 1.0, 'CPU': 16.0, 'memory': 11178012672.0, 'object_store_memory': 5589006336.0, 'GPU': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 4, 'num_gpus': 0.0}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 4 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m             This is a deprecated feature. It will be removed\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m             entirely in future versions of Flower.\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m free(): double free detected in tcache 2\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m *** SIGABRT received at time=1755823025 on cpu 15 ***\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m PC: @     0x75afa129eb2c  (unknown)  pthread_kill\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m     @     0x75afa1245330   99181696  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m     @     0x75afa124527e         32  raise\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m     @     0x75afa12288ff        192  abort\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m     @     0x75afa12297b6        288  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m     @     0x75afa12a8ff5         16  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m     @     0x75afa12ab55f         80  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m     @     0x75afa12addae         64  cfree\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m     @     0x75acb2f15e45         48  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m     @     0x75acb2f29889         48  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m     @     0x75acb2d53bcd         64  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m     @     0x75acb2d54fc5         80  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m     @     0x75acb2d15264        288  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m     @     0x75acb2dae812        208  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m     @     0x75acb2d3a71b         32  cuInit\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m     @     0x75ad94236e6a       1072  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m     @     0x75ad9423a260        304  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m     @     0x75afa12a1ed3        112  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m     @     0x75ad94283fa9         48  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m     @     0x75ad9424e1da        256  cudaGetDeviceCount\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m     @     0x75aefada5805        144  c10::cuda::device_count_ensure_non_zero()\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m     @     0x75afa1157260  (unknown)  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m [2025-08-22 08:37:05,309 E 5531 5531] logging.cc:440: *** SIGABRT received at time=1755823025 on cpu 15 ***\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m [2025-08-22 08:37:05,309 E 5531 5531] logging.cc:440: PC: @     0x75afa129eb2c  (unknown)  pthread_kill\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m [2025-08-22 08:37:05,310 E 5531 5531] logging.cc:440:     @     0x75afa1245330   99181696  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m [2025-08-22 08:37:05,310 E 5531 5531] logging.cc:440:     @     0x75afa124527e         32  raise\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m [2025-08-22 08:37:05,310 E 5531 5531] logging.cc:440:     @     0x75afa12288ff        192  abort\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m [2025-08-22 08:37:05,311 E 5531 5531] logging.cc:440:     @     0x75afa12297b6        288  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m [2025-08-22 08:37:05,311 E 5531 5531] logging.cc:440:     @     0x75afa12a8ff5         16  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m [2025-08-22 08:37:05,311 E 5531 5531] logging.cc:440:     @     0x75afa12ab55f         80  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m [2025-08-22 08:37:05,311 E 5531 5531] logging.cc:440:     @     0x75afa12addae         64  cfree\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m [2025-08-22 08:37:05,317 E 5531 5531] logging.cc:440:     @     0x75acb2f15e45         48  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m [2025-08-22 08:37:05,322 E 5531 5531] logging.cc:440:     @     0x75acb2f29889         48  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m [2025-08-22 08:37:05,327 E 5531 5531] logging.cc:440:     @     0x75acb2d53bcd         64  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m [2025-08-22 08:37:05,331 E 5531 5531] logging.cc:440:     @     0x75acb2d54fc5         80  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m [2025-08-22 08:37:05,336 E 5531 5531] logging.cc:440:     @     0x75acb2d15264        288  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m [2025-08-22 08:37:05,340 E 5531 5531] logging.cc:440:     @     0x75acb2dae812        208  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m [2025-08-22 08:37:05,340 E 5531 5531] logging.cc:440:     @     0x75acb2d3a71b         32  cuInit\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m [2025-08-22 08:37:05,340 E 5531 5531] logging.cc:440:     @     0x75ad94236e6a       1072  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m [2025-08-22 08:37:05,340 E 5531 5531] logging.cc:440:     @     0x75ad9423a260        304  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m [2025-08-22 08:37:05,340 E 5531 5531] logging.cc:440:     @     0x75afa12a1ed3        112  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m [2025-08-22 08:37:05,341 E 5531 5531] logging.cc:440:     @     0x75ad94283fa9         48  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m [2025-08-22 08:37:05,341 E 5531 5531] logging.cc:440:     @     0x75ad9424e1da        256  cudaGetDeviceCount\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m [2025-08-22 08:37:05,341 E 5531 5531] logging.cc:440:     @     0x75aefada5805        144  c10::cuda::device_count_ensure_non_zero()\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m [2025-08-22 08:37:05,343 E 5531 5531] logging.cc:440:     @     0x75afa1157260  (unknown)  (unknown)\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m Fatal Python error: Aborted\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m Stack (most recent call first):\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m   File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 372 in _lazy_init\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m   File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1341 in convert\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m   File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 942 in _apply\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m   File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 915 in _apply\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m   File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1355 in to\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m   File \"/tmp/ipykernel_1075/980544968.py\", line 16 in client_fn\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m   File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/client/client_app.py\", line 72 in adaptor_fn\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m   File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/client/message_handler/message_handler.py\", line 96 in handle_legacy_message_from_msgtype\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m   File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/client/client_app.py\", line 128 in ffn\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m   File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/client/client_app.py\", line 144 in __call__\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m   File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 58 in run\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m   File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/ray/util/tracing/tracing_helper.py\", line 467 in _resume_span\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m   File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/ray/_private/function_manager.py\", line 691 in actor_method_executor\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m   File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/ray/_private/worker.py\", line 879 in main_loop\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m   File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/ray/_private/workers/default_worker.py\", line 289 in <module>\n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=5531)\u001b[0m Extension modules: psutil._psutil_linux, psutil._psutil_posix, msgpack._cmsgpack, google._upb._message, setproctitle, yaml._yaml, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, ray._raylet, numpy._core._multiarray_umath, numpy.linalg._umath_linalg, grpc._cython.cygrpc, _cffi_backend, pyarrow.lib, pyarrow._json, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special (total: 27)\n",
      "\u001b[91mERROR \u001b[0m:     The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: ClientAppActor\n",
      "\tactor_id: 40c52f704fc6455677250b3d01000000\n",
      "\tpid: 5531\n",
      "\tnamespace: 19ca29cd-5416-4199-9b80-9e49bfa7fbde\n",
      "\tip: 172.30.170.62\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n",
      "\u001b[93mWARNING \u001b[0m:   Actor(40c52f704fc6455677250b3d01000000) will be remove from pool.\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 95, in _submit_job\n",
      "    out_mssg, updated_context = self.actor_pool.get_client_result(\n",
      "  File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 401, in get_client_result\n",
      "    return self._fetch_future_result(cid)\n",
      "  File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 291, in _fetch_future_result\n",
      "    raise ex\n",
      "  File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 282, in _fetch_future_result\n",
      "    res_cid, out_mssg, updated_context = ray.get(\n",
      "  File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/ray/_private/worker.py\", line 2639, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/ray/_private/worker.py\", line 866, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: ClientAppActor\n",
      "\tactor_id: 40c52f704fc6455677250b3d01000000\n",
      "\tpid: 5531\n",
      "\tnamespace: 19ca29cd-5416-4199-9b80-9e49bfa7fbde\n",
      "\tip: 172.30.170.62\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n",
      "\n",
      "\u001b[91mERROR \u001b[0m:     The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: ClientAppActor\n",
      "\tactor_id: 40c52f704fc6455677250b3d01000000\n",
      "\tpid: 5531\n",
      "\tnamespace: 19ca29cd-5416-4199-9b80-9e49bfa7fbde\n",
      "\tip: 172.30.170.62\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n",
      "\u001b[91mERROR \u001b[0m:     The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: ClientAppActor\n",
      "\tactor_id: 40c52f704fc6455677250b3d01000000\n",
      "\tpid: 5531\n",
      "\tnamespace: 19ca29cd-5416-4199-9b80-9e49bfa7fbde\n",
      "\tip: 172.30.170.62\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/simulation/legacy_app.py\", line 361, in start_simulation\n",
      "    hist = run_fl(\n",
      "  File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/server/server.py\", line 492, in run_fl\n",
      "    hist, elapsed_time = server.fit(\n",
      "  File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/server/server.py\", line 93, in fit\n",
      "    self.parameters = self._get_initial_parameters(server_round=0, timeout=timeout)\n",
      "  File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/server/server.py\", line 284, in _get_initial_parameters\n",
      "    get_parameters_res = random_client.get_parameters(\n",
      "  File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 170, in get_parameters\n",
      "    message_out = self._submit_job(message, timeout)\n",
      "  File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 109, in _submit_job\n",
      "    raise ex\n",
      "  File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 95, in _submit_job\n",
      "    out_mssg, updated_context = self.actor_pool.get_client_result(\n",
      "  File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 401, in get_client_result\n",
      "    return self._fetch_future_result(cid)\n",
      "  File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 291, in _fetch_future_result\n",
      "    raise ex\n",
      "  File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 282, in _fetch_future_result\n",
      "    res_cid, out_mssg, updated_context = ray.get(\n",
      "  File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/ray/_private/worker.py\", line 2639, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/syed/miniconda3/envs/flwr/lib/python3.10/site-packages/ray/_private/worker.py\", line 866, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: ClientAppActor\n",
      "\tactor_id: 40c52f704fc6455677250b3d01000000\n",
      "\tpid: 5531\n",
      "\tnamespace: 19ca29cd-5416-4199-9b80-9e49bfa7fbde\n",
      "\tip: 172.30.170.62\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n",
      "\n",
      "\u001b[91mERROR \u001b[0m:     Your simulation crashed :(. This could be because of several reasons. The most common are: \n",
      "\t > Sometimes, issues in the simulation code itself can cause crashes. It's always a good idea to double-check your code for any potential bugs or inconsistencies that might be contributing to the problem. For example: \n",
      "\t\t - You might be using a class attribute in your clients that hasn't been defined.\n",
      "\t\t - There could be an incorrect method call to a 3rd party library (e.g., PyTorch).\n",
      "\t\t - The return types of methods in your clients/strategies might be incorrect.\n",
      "\t > Your system couldn't fit a single VirtualClient: try lowering `client_resources`.\n",
      "\t > All the actors in your pool crashed. This could be because: \n",
      "\t\t - You clients hit an out-of-memory (OOM) error and actors couldn't recover from it. Try launching your simulation with more generous `client_resources` setting (i.e. it seems {'num_cpus': 4, 'num_gpus': 0.0} is not enough for your run). Use fewer concurrent actors. \n",
      "\t\t - You were running a multi-node simulation and all worker nodes disconnected. The head node might still be alive but cannot accommodate any actor with resources: {'num_cpus': 4, 'num_gpus': 0.0}.\n",
      "Take a look at the Flower simulation examples for guidance <https://flower.ai/docs/framework/how-to-run-simulations.html>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff40c52f704fc6455677250b3d01000000 Worker ID: 805b87486425c7aecfb81408c09757cfc9dc5cfddd160440a45eacee Node ID: 8d2d541bdd230be5861c1ea07ed7e6934890728bcf11694ee4d5d2a8 Worker IP address: 172.30.170.62 Worker port: 39003 Worker PID: 5531 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Simulation crashed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mActorDiedError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/simulation/legacy_app.py:361\u001b[0m, in \u001b[0;36mstart_simulation\u001b[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised, actor_type, actor_kwargs, actor_scheduling)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialized_server\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialized_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m~/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/server/server.py:492\u001b[0m, in \u001b[0;36mrun_fl\u001b[0;34m(server, config)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Train a model on the given server and return the History object.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 492\u001b[0m hist, elapsed_time \u001b[38;5;241m=\u001b[39m \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround_timeout\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/server/server.py:93\u001b[0m, in \u001b[0;36mServer.fit\u001b[0;34m(self, num_rounds, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INIT]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_initial_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting evaluation of initial global parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/server/server.py:284\u001b[0m, in \u001b[0;36mServer._get_initial_parameters\u001b[0;34m(self, server_round, timeout)\u001b[0m\n\u001b[1;32m    283\u001b[0m ins \u001b[38;5;241m=\u001b[39m GetParametersIns(config\u001b[38;5;241m=\u001b[39m{})\n\u001b[0;32m--> 284\u001b[0m get_parameters_res \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_round\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_parameters_res\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m==\u001b[39m Code\u001b[38;5;241m.\u001b[39mOK:\n",
      "File \u001b[0;32m~/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py:170\u001b[0m, in \u001b[0;36mRayActorClientProxy.get_parameters\u001b[0;34m(self, ins, timeout, group_id)\u001b[0m\n\u001b[1;32m    163\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_recorddict_in_message(\n\u001b[1;32m    164\u001b[0m     recorddict,\n\u001b[1;32m    165\u001b[0m     message_type\u001b[38;5;241m=\u001b[39mMessageTypeLegacy\u001b[38;5;241m.\u001b[39mGET_PARAMETERS,\n\u001b[1;32m    166\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    167\u001b[0m     group_id\u001b[38;5;241m=\u001b[39mgroup_id,\n\u001b[1;32m    168\u001b[0m )\n\u001b[0;32m--> 170\u001b[0m message_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_submit_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m recorddict_to_getparametersres(message_out\u001b[38;5;241m.\u001b[39mcontent, keep_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py:109\u001b[0m, in \u001b[0;36mRayActorClientProxy._submit_job\u001b[0;34m(self, message, timeout)\u001b[0m\n\u001b[1;32m    108\u001b[0m     log(ERROR, ex)\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_mssg\n",
      "File \u001b[0;32m~/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py:95\u001b[0m, in \u001b[0;36mRayActorClientProxy._submit_job\u001b[0;34m(self, message, timeout)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_pool\u001b[38;5;241m.\u001b[39msubmit_client_job(\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m a, a_fn, mssg, partition_id, context: a\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mremote(\n\u001b[1;32m     91\u001b[0m         a_fn, mssg, partition_id, context\n\u001b[1;32m     92\u001b[0m     ),\n\u001b[1;32m     93\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapp_fn, message, partition_id_str, context),\n\u001b[1;32m     94\u001b[0m )\n\u001b[0;32m---> 95\u001b[0m out_mssg, updated_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_client_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_id_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Update state\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py:401\u001b[0m, in \u001b[0;36mVirtualClientEngineActorPool.get_client_result\u001b[0;34m(self, cid, timeout)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# Fetch result belonging to the VirtualClient calling this method\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;66;03m# Return both result from tasks and (potentially) updated run context\u001b[39;00m\n\u001b[0;32m--> 401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch_future_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcid\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py:291\u001b[0m, in \u001b[0;36mVirtualClientEngineActorPool._fetch_future_result\u001b[0;34m(self, cid)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag_actor_for_removal(ex\u001b[38;5;241m.\u001b[39mactor_id)\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# Sanity check: was the result fetched generated by a client with cid=cid?\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py:282\u001b[0m, in \u001b[0;36mVirtualClientEngineActorPool._fetch_future_result\u001b[0;34m(self, cid)\u001b[0m\n\u001b[1;32m    281\u001b[0m     future: ObjectRef[Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cid_to_future[cid][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfuture\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 282\u001b[0m     res_cid, out_mssg, updated_context \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfuture\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: (str, Message, Context)\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ray\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRayActorError \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m~/miniconda3/envs/flwr/lib/python3.10/site-packages/ray/_private/auto_init_hook.py:21\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m auto_init_ray()\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/flwr/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/flwr/lib/python3.10/site-packages/ray/_private/worker.py:2639\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[38;5;66;03m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[39;00m\n\u001b[0;32m-> 2639\u001b[0m values, debugger_breakpoint \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2640\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(values):\n",
      "File \u001b[0;32m~/miniconda3/envs/flwr/lib/python3.10/site-packages/ray/_private/worker.py:866\u001b[0m, in \u001b[0;36mWorker.get_objects\u001b[0;34m(self, object_refs, timeout)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 866\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m    867\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values, debugger_breakpoint\n",
      "\u001b[0;31mActorDiedError\u001b[0m: The actor died unexpectedly before finishing this task.\n\tclass_name: ClientAppActor\n\tactor_id: 40c52f704fc6455677250b3d01000000\n\tpid: 5531\n\tnamespace: 19ca29cd-5416-4199-9b80-9e49bfa7fbde\n\tip: 172.30.170.62\nThe actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 119\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m⚠️ Could not generate summary. No centralized metrics found. Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# Make sure to copy all the helper functions and classes defined above\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 74\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Starting Flower simulation with Pareto Strategy...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# 1. CAPTURE the History object returned by the simulation\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTOTAL_CLIENTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mServerConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_resources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_cpus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_gpus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# --- NEW: Process, Print, and Save the Final Results ---\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/flwr/lib/python3.10/site-packages/flwr/simulation/legacy_app.py:397\u001b[0m, in \u001b[0;36mstart_simulation\u001b[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised, actor_type, actor_kwargs, actor_scheduling)\u001b[0m\n\u001b[1;32m    367\u001b[0m     log(ERROR, traceback\u001b[38;5;241m.\u001b[39mformat_exc())\n\u001b[1;32m    368\u001b[0m     log(\n\u001b[1;32m    369\u001b[0m         ERROR,\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour simulation crashed :(. This could be because of several reasons. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m         client_resources,\n\u001b[1;32m    396\u001b[0m     )\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimulation crashed.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mex\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;66;03m# Stop time monitoring resources in cluster\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     f_stop\u001b[38;5;241m.\u001b[39mset()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Simulation crashed."
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # --- Load Data ---\n",
    "    print(\"✅ Loading data for all clients...\")\n",
    "    all_data = loadClientsData()\n",
    "    X_train_csv, X_test_csv, Y_train_csv, Y_test_csv, \\\n",
    "    X_train_1, X_test_1, Y_train_1, Y_test_1, \\\n",
    "    X_train_2, X_test_2, Y_train_2, Y_test_2 = all_data\n",
    "    TOTAL_CLIENTS = len(X_train_csv)\n",
    "    print(f\"✅ Data for {TOTAL_CLIENTS} clients loaded successfully.\")\n",
    "\n",
    "    # --- Client Factory ---\n",
    "    # In your main function\n",
    "\n",
    "    def client_fn(cid: str) -> fl.client.Client: # Return type is now fl.client.Client\n",
    "        client_id = int(cid)\n",
    "        net = ModelCSVIMG(num_csv_features=X_train_csv[client_id].shape[1], img_shape1=32, img_shape2=32).to(DEVICE)\n",
    "        train_dataset = CustomDatasetRes(X_train_csv[client_id], X_train_1[client_id], X_train_2[client_id], Y_train_csv[client_id])\n",
    "        val_dataset = CustomDatasetRes(X_test_csv[client_id], X_test_1[client_id], X_test_2[client_id], Y_test_csv[client_id])\n",
    "        trainloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        valloader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "        # Instantiate your NumPyClient\n",
    "        numpy_client = FlowerClient(client_id, net, trainloader, valloader)\n",
    "        \n",
    "        # NEW: Convert it to a Flower Client and return\n",
    "        return numpy_client.to_client()\n",
    "        \n",
    "    # --- Prepare the data for the server's evaluation function ---\n",
    "    # Create a tuple containing all the test set arrays for every client\n",
    "    server_test_data = (X_test_csv, X_test_1, X_test_2, Y_test_csv)\n",
    "    \n",
    "    # --- Server-side Evaluation (optional but good practice) ---\n",
    "    # In your main function, where you define get_evaluate_fn\n",
    "\n",
    "    def get_evaluate_fn(test_data_splits):\n",
    "        \"\"\"Return an evaluation function for server-side evaluation.\"\"\"\n",
    "        def evaluate(server_round: int, parameters: fl.common.NDArrays, config: dict):\n",
    "            net = ModelCSVIMG(num_csv_features=test_data_splits[0][0].shape[1], img_shape1=32, img_shape2=32).to(DEVICE)\n",
    "\n",
    "            server_test_cid = TOTAL_CLIENTS - 1\n",
    "            params_dict = zip(net.state_dict().keys(), parameters)\n",
    "            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "            net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "            test_dataset = CustomDatasetRes(test_data_splits[0][server_test_cid], test_data_splits[1][server_test_cid],\n",
    "                                          test_data_splits[2][server_test_cid], test_data_splits[3][server_test_cid])\n",
    "            testloader = DataLoader(test_dataset, batch_size=32)\n",
    "            loss, accuracy = test(net, testloader)\n",
    "            \n",
    "            # NEW: More prominent end-of-round summary\n",
    "            print(\"=\"*60)\n",
    "            print(f\"✅ ROUND {server_round} SUMMARY - Global Model Performance:\")\n",
    "            print(f\"   Loss: {loss:.4f} | Accuracy: {accuracy:.4f}\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            return loss, {\"accuracy\": accuracy}\n",
    "        return evaluate\n",
    "\n",
    "    # --- Instantiate and use the ParetoStrategy ---\n",
    "    # In your main function\n",
    "    strategy = ParetoStrategy(\n",
    "        fraction_fit=0.5,\n",
    "        min_fit_clients=4,\n",
    "        fraction_evaluate=0.0,      # <-- CORRECTED\n",
    "        min_evaluate_clients=0,     # <-- CORRECTED\n",
    "        min_available_clients=TOTAL_CLIENTS,\n",
    "        evaluate_fn=get_evaluate_fn(server_test_data),\n",
    "    )\n",
    "\n",
    "    # --- Start Simulation ---\n",
    "    print(\"✅ Starting Flower simulation with Pareto Strategy...\")\n",
    "    \n",
    "    # 1. CAPTURE the History object returned by the simulation\n",
    "    history = fl.simulation.start_simulation(\n",
    "        client_fn=client_fn,\n",
    "        num_clients=TOTAL_CLIENTS,\n",
    "        config=fl.server.ServerConfig(num_rounds=10),\n",
    "        strategy=strategy,\n",
    "        client_resources={\"num_cpus\": 4, \"num_gpus\": 0.25 if torch.cuda.is_available() else 0},\n",
    "    )\n",
    "\n",
    "\n",
    "    # --- NEW: Process, Print, and Save the Final Results ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"              SIMULATION COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 2. EXTRACT loss and accuracy from the History object\n",
    "    # The history object contains metrics from the server-side evaluation (centralized)\n",
    "    try:\n",
    "        # Get accuracy values from history\n",
    "        rounds, accuracies = zip(*history.metrics_centralized[\"accuracy\"])\n",
    "        # Get loss values from history\n",
    "        _, losses = zip(*history.losses_centralized)\n",
    "\n",
    "        # 3. CREATE a pandas DataFrame\n",
    "        summary_df = pd.DataFrame({\n",
    "            \"Round\": rounds,\n",
    "            \"Loss\": losses,\n",
    "            \"Accuracy\": accuracies\n",
    "        })\n",
    "\n",
    "        # 4. PRINT the summary table\n",
    "        print(\"\\n📈 Global Model Performance Summary:\")\n",
    "        print(summary_df.to_string(index=False))\n",
    "\n",
    "        # 5. SAVE the summary to a CSV file\n",
    "        csv_filename = \"simulation_summary.csv\"\n",
    "        summary_df.to_csv(csv_filename, index=False)\n",
    "        print(f\"\\n✅ Summary successfully saved to: {csv_filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n⚠️ Could not generate summary. No centralized metrics found. Error: {e}\")\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Make sure to copy all the helper functions and classes defined above\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5337d49e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flwr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
